{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7ef64e",
   "metadata": {},
   "source": [
    "# Using Multiclass Text Classification to Analyze Famous Quotes \n",
    "\n",
    "#### Gokul Prasad & Hoang Nguyen \n",
    "#### LIGN 167, Winter 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998fd17",
   "metadata": {},
   "source": [
    "In this project, we'll aim to classify a variety of quotes with tags that refer to certain themes or elements specific to that particular quote. \n",
    "\n",
    "For example, Albert Einstein's quote “Life is like riding a bicycle. To keep your balance, you must keep moving.” would have tags like \"life\" or \"simile\" because it contains thematic elements about life, and contains a simile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1773b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim as gm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "#nltk.download('punkt')\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b1c8b6",
   "metadata": {},
   "source": [
    "# Scraping and Cleaning the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efa41f",
   "metadata": {},
   "source": [
    "We'll be sourcing our data from http://quotes.toscrape.com. This is a website containing 11 pages worth of quotes, each of them classified with a few tags. \n",
    "\n",
    "Firstly, we'll loop through the pages, and scrape the website HTML data with BeautifulSoup. Then, we'll use lambda functions to pull author data, quote data, and tag data. We'll put each of these into lists, and then create a pandas DataFrame to hold all our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9738cafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>[change, deep-thoughts, thinking, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>[abilities, choices]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>[inspirational, life, live, miracle, miracles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>[aliteracy, books, classic, humor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>[be-yourself, inspirational]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Author                                              Quote  \\\n",
       "0  Albert Einstein  “The world as we have created it is a process ...   \n",
       "1     J.K. Rowling  “It is our choices, Harry, that show what we t...   \n",
       "2  Albert Einstein  “There are only two ways to live your life. On...   \n",
       "3      Jane Austen  “The person, be it gentleman or lady, who has ...   \n",
       "4   Marilyn Monroe  “Imperfection is beauty, madness is genius and...   \n",
       "\n",
       "                                             Tags  \n",
       "0        [change, deep-thoughts, thinking, world]  \n",
       "1                            [abilities, choices]  \n",
       "2  [inspirational, life, live, miracle, miracles]  \n",
       "3              [aliteracy, books, classic, humor]  \n",
       "4                    [be-yourself, inspirational]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = 1\n",
    "\n",
    "authors_lst = []\n",
    "quotes_lst = []\n",
    "tags_lst = []\n",
    "\n",
    "\n",
    "while page < 11: \n",
    "    url = 'http://quotes.toscrape.com/page/{}'.format(page)\n",
    "    scrape = requests.get(url)\n",
    "    parsed = BeautifulSoup(scrape.content, \"html.parser\")\n",
    "    \n",
    "    curr_authors = list(map(lambda x: x.text, parsed.find_all(class_ = \"author\")))\n",
    "    curr_quotes = list(map(lambda x: x.text, parsed.find_all(class_ = 'text')))\n",
    "    \n",
    "    tag_groups = parsed.find_all(\"div\", class_ = \"tags\")\n",
    "\n",
    "    curr_tags = []\n",
    "    for i in range(len(tag_groups)):\n",
    "\n",
    "        tags = tag_groups[i].find_all(\"a\", class_ = \"tag\")\n",
    "\n",
    "        curr_group = []\n",
    "        for tag in tags:\n",
    "\n",
    "            curr_group.append(tag.text)\n",
    "\n",
    "        curr_tags.append(curr_group)\n",
    "    \n",
    "    authors_lst += curr_authors\n",
    "    quotes_lst += curr_quotes\n",
    "    tags_lst += curr_tags\n",
    "    \n",
    "    page += 1\n",
    "    \n",
    "data = {\"Author\":authors_lst, \"Quote\":quotes_lst, \"Tags\":tags_lst}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289aba52",
   "metadata": {},
   "source": [
    "As we can see, our dataset contains some pretty messy strings in all 3 columns. We'll need to process the data to make sure it's usable for our modeling later on. \n",
    "\n",
    "For quotes, we'll first make all characters lowercase, and then use regex functionality to substitute any non alphanumeric / whitespace character with a blank string. \n",
    "\n",
    "For example, if we input a quote like \"I love. LIGN 167!!?\" we would receive an output of \"i love lign 167\". We'll apply this to our Author and Quote columns to clean them up and make them much more simplified strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6bbad6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quotes_cleaning(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub('[^A-Za-z0-9\\s]', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['Quote'] = df['Quote'].apply(quotes_cleaning)\n",
    "df['Author'] = df['Author'].apply(quotes_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a10b2c",
   "metadata": {},
   "source": [
    "For the tags, we have to a slightly more complicated function since the data is tucked into lists. Firstly, we'll make it a string, and use regex to remove the surrounding brackets, remove non-word characters, and replace all multi-whitespaces with a single space. We'll then render the string as a list again, and return the list. \n",
    "\n",
    "For example, if we input a list like [deep?, wonderous.., love-happy], we would get an output of [deep, wonderous, love, happy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7baedccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_cleaning(text):\n",
    "    \n",
    "    text = re.sub('[\\[ \\]]', ' ', str(text))\n",
    "    text = re.sub('[^\\w]', ' ', text)\n",
    "    text = re.sub('[\\s]', ' ', text)\n",
    "    \n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text.split(' ')\n",
    "\n",
    "df['Tags'] = df['Tags'].apply(tags_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f4e5cf",
   "metadata": {},
   "source": [
    "Now, having cleaned the dataset more fully, we can see the impact on our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982252e6",
   "metadata": {},
   "source": [
    "# Reshaping Data for Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b9174",
   "metadata": {},
   "source": [
    "Now, while the data is cleaned, we can't really model accurately when our tags are all in a list. Inputting them into our sklearn Pipelines later would not work as we would want, so we have to find a way to reshape the dataframe. Firstly, we'll need to collect the minimum and maximum amount of tags, which we do as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "708238d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lens = df['Tags'].apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc3047",
   "metadata": {},
   "source": [
    "So we see that the maximum amount of tags a quote could have would be 11 tags. So, let's generate a function that will make each list of tags equivalent by adding the necessary number of None values to make it to a list of length 11. \n",
    "\n",
    "For example, an input of [life, duck, nature] would yield [life, duck, nature, None, None, None, None, None, None, None, None]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7cf95757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_to_column(tags):\n",
    "    \n",
    "    sub = 11 - len(tags)\n",
    "        \n",
    "    total = tags + [None] * sub\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f200c1a6",
   "metadata": {},
   "source": [
    "Now we can apply that function to our Tags column, and use pandas get_dummies() functionality to reshape our dataframe to where each tag is a column, and the column contains 1s or 0s, reflecting whether or not a particular tag is in the quote belonging to that row. \n",
    "\n",
    "We then combine this dataframe with our original dataframe, and drop our tags columns. We can see the finished result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa43dfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Quote</th>\n",
       "      <th>tag_</th>\n",
       "      <th>tag_abilities</th>\n",
       "      <th>tag_activism</th>\n",
       "      <th>tag_adulthood</th>\n",
       "      <th>tag_adventure</th>\n",
       "      <th>tag_age</th>\n",
       "      <th>tag_alcohol</th>\n",
       "      <th>tag_aliteracy</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_plans</th>\n",
       "      <th>tag_truth</th>\n",
       "      <th>tag_writers</th>\n",
       "      <th>tag_love</th>\n",
       "      <th>tag_peace</th>\n",
       "      <th>tag_philosophy</th>\n",
       "      <th>tag_writing</th>\n",
       "      <th>tag_marriage</th>\n",
       "      <th>tag_unhappy</th>\n",
       "      <th>tag_marriage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert einstein</td>\n",
       "      <td>the world as we have created it is a process o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jk rowling</td>\n",
       "      <td>it is our choices harry that show what we trul...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albert einstein</td>\n",
       "      <td>there are only two ways to live your life one ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Author                                              Quote  tag_  \\\n",
       "0  albert einstein  the world as we have created it is a process o...     0   \n",
       "1       jk rowling  it is our choices harry that show what we trul...     0   \n",
       "2  albert einstein  there are only two ways to live your life one ...     0   \n",
       "\n",
       "   tag_abilities  tag_activism  tag_adulthood  tag_adventure  tag_age  \\\n",
       "0              0             0              0              0        0   \n",
       "1              1             0              0              0        0   \n",
       "2              0             0              0              0        0   \n",
       "\n",
       "   tag_alcohol  tag_aliteracy  ...  tag_plans  tag_truth  tag_writers  \\\n",
       "0            0              0  ...          0          0            0   \n",
       "1            0              0  ...          0          0            0   \n",
       "2            0              0  ...          0          0            0   \n",
       "\n",
       "   tag_love  tag_peace  tag_philosophy  tag_writing  tag_marriage  \\\n",
       "0         0          0               0            0             0   \n",
       "1         0          0               0            0             0   \n",
       "2         0          0               0            0             0   \n",
       "\n",
       "   tag_unhappy  tag_marriage  \n",
       "0            0             0  \n",
       "1            0             0  \n",
       "2            0             0  \n",
       "\n",
       "[3 rows x 201 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_renames = {0:'tag_1',1:'tag_2',2:'tag_3',3:'tag_4',4:'tag_5',5:'tag_6',6:'tag_7',7:'tag_8',8:'tag_9',9:'tag_10', 10:'tag_11',}\n",
    "\n",
    "tags = pd.DataFrame(df['Tags'].apply(tag_to_column).tolist()).rename(columns = column_renames)\n",
    "\n",
    "tags_df = pd.get_dummies(tags, prefix = 'tag')\n",
    "combined = pd.concat([df, tags_df], axis = 1).drop(columns = ['Tags'])\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b11d4a",
   "metadata": {},
   "source": [
    "We can see the distribution of tags as below. 31% of our quotes only have 1 tag, while only 1% have the maximum tags possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b538dc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.31\n",
       "2     0.23\n",
       "3     0.20\n",
       "4     0.11\n",
       "5     0.06\n",
       "6     0.03\n",
       "8     0.03\n",
       "7     0.02\n",
       "11    0.01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rowsums = combined.iloc[:,2:].sum(axis=1)\n",
    "cnt = rowsums.value_counts()\n",
    "\n",
    "cnt.plot(kind = 'bar')\n",
    "cnt / cnt.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0454d",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2adcc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67,)\n",
      "(33,)\n"
     ]
    }
   ],
   "source": [
    "categories = combined.columns.tolist()[2:]\n",
    "\n",
    "train, test = train_test_split(combined, random_state=42, test_size=0.33, shuffle=True)\n",
    "\n",
    "X_train = train.Quote\n",
    "X_test = test.Quote\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6d3b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "\n",
    "\n",
    "\n",
    "accuracies = {}\n",
    "for category in categories:\n",
    "    \n",
    "    NB_pipeline.fit(X_train, train[category])\n",
    "    prediction = NB_pipeline.predict(X_test)\n",
    "    acc = NB_pipeline.score(X_test, test[category])\n",
    "    #acc = accuracy_score(test[category], prediction)\n",
    "    accuracies[category] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5590eb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9818624198186241"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(accuracies.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
