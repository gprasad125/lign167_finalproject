{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gprasad125/lign167_finalproject/blob/main/Copy_of_Project_Tester.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f7ef64e",
      "metadata": {
        "id": "5f7ef64e"
      },
      "source": [
        "# Using Multiclass Text Classification to Analyze Famous Quotes \n",
        "\n",
        "#### Gokul Prasad & Hoang Nguyen \n",
        "#### LIGN 167, Winter 2022"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8998fd17",
      "metadata": {
        "id": "8998fd17"
      },
      "source": [
        "In this project, we'll aim to classify a variety of quotes with tags that refer to certain themes or elements specific to that particular quote. \n",
        "\n",
        "For example, Albert Einstein's quote “Life is like riding a bicycle. To keep your balance, you must keep moving.” would have tags like \"life\" or \"simile\" because it contains thematic elements about life, and contains a simile. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1773b1c2",
      "metadata": {
        "id": "1773b1c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0963ab83-c887-4190-cf92-3177b1144f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "# Scraping\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time \n",
        "\n",
        "# Data manipulation / cleaning / visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim as gm\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "import re \n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# Sklearn modeling\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# keras / tensorflow modeling\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Embedding, TextVectorization, StringLookup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "from keras.metrics import Precision, Recall\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.data import AUTOTUNE\n",
        "from tensorflow.data import Dataset\n",
        "from tensorflow.ragged import constant\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Transformers for model 2.2\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import AutoTokenizer,TFBertModel\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2b1c8b6",
      "metadata": {
        "id": "f2b1c8b6"
      },
      "source": [
        "# Scraping and Cleaning the Data "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5efa41f",
      "metadata": {
        "id": "f5efa41f"
      },
      "source": [
        "We'll be sourcing our data from https://www.goodreads.com/quotes. This is a website containing 100 pages worth of quotes, each of them classified with a few tags. \n",
        "\n",
        "Firstly, we'll loop through the pages, and scrape the website HTML data with BeautifulSoup. Then, we'll use lambda functions to pull author data, quote data, and tag data. We'll put each of these into lists, and then create a pandas DataFrame to hold all our data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9738cafb",
      "metadata": {
        "id": "9738cafb"
      },
      "outputs": [],
      "source": [
        "goodreads_quotes = []\n",
        "goodreads_tags = []\n",
        "\n",
        "for i in range(1, 101):\n",
        "\n",
        "  url = 'https://www.goodreads.com/quotes?page={}'.format(i)\n",
        "\n",
        "  time.sleep(5)\n",
        "  scrape = requests.get(url)\n",
        "  parsed = BeautifulSoup(scrape.content, 'html.parser')\n",
        "\n",
        "  elements_quotes = parsed.find_all('div', class_ = \"quoteText\")\n",
        "  \n",
        "  quotes = [x.text.strip() for x in elements_quotes]\n",
        "  tags = parsed.find_all(class_ = 'quoteFooter')\n",
        "\n",
        "  goodreads_quotes += quotes\n",
        "  goodreads_tags += tags"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'quote':goodreads_quotes, 'tags':goodreads_tags}\n",
        "goodreads = pd.DataFrame(data)\n",
        "goodreads.head()"
      ],
      "metadata": {
        "id": "jZMT3V2z8r-u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "790ed52f-7762-4406-d222-db8bf84d8310"
      },
      "id": "jZMT3V2z8r-u",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               quote  \\\n",
              "0  “Be yourself; everyone else is already taken.”...   \n",
              "1  “I'm selfish, impatient and a little insecure....   \n",
              "2  “Two things are infinite: the universe and hum...   \n",
              "3  “So many books, so little time.”\\n    ―\\n  \\n ...   \n",
              "4  “A room without books is like a body without a...   \n",
              "\n",
              "                                                tags  \n",
              "0  [\\n, [\\n     tags:\\n       , [attributed-no-so...  \n",
              "1  [\\n, [\\n     tags:\\n       , [attributed-no-so...  \n",
              "2  [\\n, [\\n     tags:\\n       , [attributed-no-so...  \n",
              "3  [\\n, [\\n     tags:\\n       , [books], ,\\n     ...  \n",
              "4  [\\n, [\\n     tags:\\n       , [attributed-no-so...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52428f08-1a4b-4ed1-82f4-ef7942f17234\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Be yourself; everyone else is already taken.”...</td>\n",
              "      <td>[\\n, [\\n     tags:\\n       , [attributed-no-so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“I'm selfish, impatient and a little insecure....</td>\n",
              "      <td>[\\n, [\\n     tags:\\n       , [attributed-no-so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“Two things are infinite: the universe and hum...</td>\n",
              "      <td>[\\n, [\\n     tags:\\n       , [attributed-no-so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“So many books, so little time.”\\n    ―\\n  \\n ...</td>\n",
              "      <td>[\\n, [\\n     tags:\\n       , [books], ,\\n     ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“A room without books is like a body without a...</td>\n",
              "      <td>[\\n, [\\n     tags:\\n       , [attributed-no-so...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52428f08-1a4b-4ed1-82f4-ef7942f17234')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52428f08-1a4b-4ed1-82f4-ef7942f17234 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52428f08-1a4b-4ed1-82f4-ef7942f17234');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "289aba52",
      "metadata": {
        "id": "289aba52"
      },
      "source": [
        "As we can see, our dataset contains some pretty messy strings in both columns. We'll need to process the data to make sure it's usable for our modeling later on. \n",
        "\n",
        "For quotes, we'll first make all characters lowercase, and then use regex functionality to substitute any non alphanumeric / whitespace character with a blank string. \n",
        "\n",
        "For example, if we input a quote like \"I love. LIGN \\n167!!?   \\n \\nOscar Wilde \" we would receive an output of \"i love lign 167\". We'll apply this to our Author and Quote columns to clean them up and make them much more simplified strings. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6bbad6f0",
      "metadata": {
        "id": "6bbad6f0"
      },
      "outputs": [],
      "source": [
        "def quotes_cleaning(text):\n",
        "    \n",
        "    text = text.lower()\n",
        "    \n",
        "    text = re.sub('[^A-Za-z0-9\\s]', '', text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "def tags_cleaning(text):\n",
        "    \n",
        "    text = re.sub('[\\[ \\]]', ' ', str(text))\n",
        "    text = re.sub('[^\\w]', ' ', text)\n",
        "    text = re.sub('[\\s]', ' ', text)\n",
        "    text = re.sub('[0-9]', ' ', text)\n",
        "    \n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    return text.split(' ')\n",
        "\n",
        "def remove_author(quote):\n",
        "\n",
        "  if quote[0] == '“':\n",
        "\n",
        "    end_of_quote = quote.index('”')\n",
        "    quote = quote[1:end_of_quote]\n",
        "\n",
        "  return quote\n",
        "\n",
        "def bs_to_list(tags):\n",
        "\n",
        "  if type(tags) != list:\n",
        "\n",
        "    tags = tags.find_all('a')\n",
        "  \n",
        "    tag_strs = []\n",
        "    for tag in tags[:-1]:\n",
        "\n",
        "      tag = str(tag)\n",
        "      start_idx = tag.index('\">')\n",
        "      end_idx = tag.index('</')\n",
        "      tag = tag[start_idx + 2:end_idx]\n",
        "      tag_strs.append(tag)\n",
        "\n",
        "    tags = tag_strs\n",
        "\n",
        "  return tags"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86a10b2c",
      "metadata": {
        "id": "86a10b2c"
      },
      "source": [
        "For the tags, we have to a slightly more complicated function since the data is tucked into lists. Firstly, we'll make it a string, and use regex to remove the surrounding brackets, remove non-word characters, and replace all multi-whitespaces with a single space. We'll then render the string as a list again, and return the list. \n",
        "\n",
        "For example, if we input a list like [deep?, wonderous.., love-happy], we would get an output of [deep, wonderous, love, happy]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7baedccc",
      "metadata": {
        "id": "7baedccc"
      },
      "outputs": [],
      "source": [
        "goodreads['quote'] = goodreads['quote'].apply(remove_author)\n",
        "goodreads['quote'] = goodreads['quote'].apply(quotes_cleaning)\n",
        "goodreads['tags'] = goodreads['tags'].apply(bs_to_list)\n",
        "goodreads['tags'] = goodreads['tags'].apply(tags_cleaning)\n",
        "\n",
        "isEmpty = goodreads['tags'].apply(lambda x: '' in x)\n",
        "goodreads['isEmpty'] = isEmpty"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55f4e5cf",
      "metadata": {
        "id": "55f4e5cf"
      },
      "source": [
        "Now, having cleaned the dataset more fully, we can see the impact on our data. We've also added an isEmpty column, which marks whether or not the quote has no tags. Since the tags are in a list, empty lists will exist as \"[ ]\" and not as a NaN value.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "21f6be24",
      "metadata": {
        "id": "21f6be24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "e073fe59-26af-45bc-d85d-48774bde7783"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               quote  \\\n",
              "0         be yourself everyone else is already taken   \n",
              "1  im selfish impatient and a little insecure i m...   \n",
              "2  two things are infinite the universe and human...   \n",
              "3                       so many books so little time   \n",
              "\n",
              "                                                tags  isEmpty  \n",
              "0  [attributed, no, source, be, yourself, gilbert...    False  \n",
              "1  [attributed, no, source, best, life, love, mis...    False  \n",
              "2  [attributed, no, source, human, nature, humor,...    False  \n",
              "3                                     [books, humor]    False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c576a5c-6de4-4c3b-86b6-432e204af092\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "      <th>tags</th>\n",
              "      <th>isEmpty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>be yourself everyone else is already taken</td>\n",
              "      <td>[attributed, no, source, be, yourself, gilbert...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im selfish impatient and a little insecure i m...</td>\n",
              "      <td>[attributed, no, source, best, life, love, mis...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>two things are infinite the universe and human...</td>\n",
              "      <td>[attributed, no, source, human, nature, humor,...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>so many books so little time</td>\n",
              "      <td>[books, humor]</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c576a5c-6de4-4c3b-86b6-432e204af092')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c576a5c-6de4-4c3b-86b6-432e204af092 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c576a5c-6de4-4c3b-86b6-432e204af092');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "goodreads.head(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "982252e6",
      "metadata": {
        "id": "982252e6"
      },
      "source": [
        "# Reshaping Data for Modeling "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce5b9174",
      "metadata": {
        "id": "ce5b9174"
      },
      "source": [
        "Now, while the data is cleaned, we can't really model accurately when our tags are all in a list. Inputting them into our sklearn Pipelines later would not work as we would want, so we have to find a way to reshape the dataframe. Firstly, we'll need to collect the minimum and maximum amount of tags, which we do as follows. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "708238d7",
      "metadata": {
        "scrolled": true,
        "id": "708238d7"
      },
      "outputs": [],
      "source": [
        "max_tags = goodreads['tags'].apply(lambda x: len(x)).max()\n",
        "max_tags"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12fc3047",
      "metadata": {
        "id": "12fc3047"
      },
      "source": [
        "So we see that the maximum amount of tags a quote could have would be 48 tags. So, let's generate a function that will make each list of tags equivalent by adding the necessary number of None values to make it to a list of length 48. \n",
        "\n",
        "For example, an input of [life, duck, nature] would yield [life, duck, nature, None, None, None, None, None, None, None, None, ... None, None, None]. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cf95757",
      "metadata": {
        "id": "7cf95757"
      },
      "outputs": [],
      "source": [
        "def pad(tags):\n",
        "\n",
        "  needed = 48 - len(tags)\n",
        "  tags = tags + ([None] * needed)\n",
        "\n",
        "  return tags"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f200c1a6",
      "metadata": {
        "id": "f200c1a6"
      },
      "source": [
        "Now we can apply that function to our Tags column, and use pandas get_dummies() functionality to reshape our dataframe to where each tag is a column, and the column contains 1s or 0s, reflecting whether or not a particular tag is in the quote belonging to that row. \n",
        "\n",
        "Unfortunately, pd.get_dummies() will create some duplicates so we'll groupby and sum to combine the duplicate tag columns. \n",
        "\n",
        "We then combine this dataframe with our original dataframe, and drop our tags columns. We can see the finished result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa43dfb7",
      "metadata": {
        "scrolled": true,
        "id": "aa43dfb7"
      },
      "outputs": [],
      "source": [
        "gr_tags = pd.DataFrame(goodreads['tags'].apply(pad).tolist())\n",
        "gr_tags_oh = pd.get_dummies(gr_tags, prefix = 'tags')\n",
        "gr_tags_oh = gr_tags_oh.groupby(gr_tags_oh.columns, axis = 1).sum()\n",
        "reshaped_gr = pd.concat([goodreads, gr_tags_oh], axis = 1).drop(columns = ['isEmpty', 'tags'])\n",
        "reshaped_gr.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45b11d4a",
      "metadata": {
        "id": "45b11d4a"
      },
      "source": [
        "We can see the distribution of tags as below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b538dc55",
      "metadata": {
        "id": "b538dc55"
      },
      "outputs": [],
      "source": [
        "cnts = reshaped_gr.iloc[:, 1:].sum(axis = 1)\n",
        "cnts.hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbd0454d",
      "metadata": {
        "id": "cbd0454d"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f709dcc",
      "metadata": {
        "id": "6f709dcc"
      },
      "source": [
        "Now, we can begin our modeling. \n",
        "\n",
        "Firstly, we'll get a list of all of our tags. We'll do this by taking all columns besides \"Quote\"\n",
        "\n",
        "Next, we'll use sklearn's train_test_split() function to split our dataset into a training and testing set. We'll split so that our test set is 33% of our dataset size. As we have 100 rows into our data, then we'll have a training set of 67 rows and testing size of 33 rows. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2adcc28",
      "metadata": {
        "id": "a2adcc28"
      },
      "outputs": [],
      "source": [
        "gr_tags = reshaped_gr.columns[1:]\n",
        "\n",
        "train, test = train_test_split(reshaped_gr, test_size = 0.25, random_state = 42)\n",
        "\n",
        "x_tr = train.quote\n",
        "x_te = test.quote\n",
        "\n",
        "print(x_tr.shape)\n",
        "print(x_te.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42696382",
      "metadata": {
        "id": "42696382"
      },
      "source": [
        "### Model 1: Decision Tree Classifier\n",
        "\n",
        "Our first model will be using scikit-learn Pipelines. \n",
        "\n",
        "Inside our pipeline, we'll firstly vectorize the input data by converting the quote to their TFIDF formation. This will convert our string Quotes to becoming numerical values for input. Then, we have to consider how we will be handling multiple classes. We'll try with a OneVsRest classifier, because this will allow us to pass in each tag and use an single-class estimator on each tag's train and test data. \n",
        "\n",
        "However, we need to wrap the OneVsRest classifier around an estimator that makes sense for what we are trying to achieve here. We'll use a Decision tree classifier, because the sklearn functionality is pretty simplistic, doesnt require much shaping of the data, and should hopefully set a good basis for our first try. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6d3b9cf",
      "metadata": {
        "id": "f6d3b9cf"
      },
      "outputs": [],
      "source": [
        "dt_classifier = Pipeline([('tfidf', TfidfVectorizer()), ('clf', OneVsRestClassifier(DecisionTreeClassifier()))])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcfc7702",
      "metadata": {
        "id": "dcfc7702"
      },
      "source": [
        "Now, we'll loop through each of the tags in our dataset, train our model on that particular tag, and then append it to a dictionary containg each tag and that tag's associated evaluation score. \n",
        "\n",
        "For our evaluating metric, we'll choose to use f1 scores over accuracy, because if we look at our data, we have an imbalance of tags. Some quotes have several tags, while others only have one or two. As such, using accuracy would likely not work well for this scenario. \n",
        "\n",
        "However, we have multiple classes, so it would not make much sense to get a bunch of f1 scores since each tag would give different results. We can instead collect each tag's precision and recall from when the model's predictions are compared to the actual test data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29223acb",
      "metadata": {
        "id": "29223acb"
      },
      "outputs": [],
      "source": [
        "prec_recs = {}\n",
        "for tag in gr_tags:\n",
        "    \n",
        "    dt_classifier.fit(x_tr, train[tag])\n",
        "    prediction = dt_classifier.predict(x_te)\n",
        "    \n",
        "    precision_recall = precision_recall_fscore_support(test[tag], prediction, average = 'macro')\n",
        "    prec_recs[tag] = precision_recall"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42c71ad3",
      "metadata": {
        "id": "42c71ad3"
      },
      "source": [
        "So now we can calculate the average precision and recall for our tags by looping through our dictionary, summing up the total of both metrics, and dividing by the number of tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5590eb64",
      "metadata": {
        "id": "5590eb64"
      },
      "outputs": [],
      "source": [
        "sum_precision = 0\n",
        "sum_recall = 0\n",
        "\n",
        "for key in prec_recs.keys():\n",
        "    \n",
        "    sum_precision += prec_recs[key][0]\n",
        "    sum_recall += prec_recs[key][1]\n",
        "    \n",
        "mean_precision = sum_precision / len(prec_recs.keys())\n",
        "mean_recall = sum_recall / len(prec_recs.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8f60216",
      "metadata": {
        "id": "d8f60216"
      },
      "source": [
        "Now we apply the formula of finding an f1 score which is (2 * p * r) / (p + r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d942fa49",
      "metadata": {
        "id": "d942fa49"
      },
      "outputs": [],
      "source": [
        "average_f1 = (2 * mean_precision * mean_recall) / (mean_precision + mean_recall)\n",
        "average_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6039cf1",
      "metadata": {
        "id": "c6039cf1"
      },
      "source": [
        "So we have an f1 score of about 0.708. F1 scores range from 0 to 1, and the closer they are to 1, the better the model, so we have set up a good baseline for ourselves. But we want to improve on this and make our model better classify our quotes. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93fd599",
      "metadata": {
        "id": "b93fd599"
      },
      "source": [
        "#### Optimizing Model 1  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68c5ea4e",
      "metadata": {
        "id": "68c5ea4e"
      },
      "source": [
        "Now that we have our baseline model, how can we optimize it? \n",
        "\n",
        "There are many concepts we can implement into our Pipeline, both from a text classification standpoint, as well as a sklearn standpoint. \n",
        "\n",
        "The first method we'll implement is getting rid of stop-words. These are words that appear extremely frequently in human language, and give very little value to our model. Removing them can allow our model to focus more strongly on the more important data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41bbe4f3",
      "metadata": {
        "id": "41bbe4f3"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "919b4ad4",
      "metadata": {
        "id": "919b4ad4"
      },
      "source": [
        "Now that we have defined the words to remove, we can try and optimize our other parameters with GridSearchCV. First, we'll need to select what parameters we can optimize. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07867f2b",
      "metadata": {
        "id": "07867f2b"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'clf':(DecisionTreeClassifier(),),\n",
        "    'clf__max_depth': [2, 3, 4, 5, 7, 10, 13, 15, 18, None],\n",
        "    'clf__min_samples_split': [2, 3, 5, 7, 10, 15, 20],\n",
        "    'clf__min_samples_leaf': [2, 3, 5, 7, 10, 15, 20]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7342d553",
      "metadata": {
        "id": "7342d553"
      },
      "source": [
        "Now we have created the parameters, we can place that into a GridSearchCV and train it on our data. \n",
        "Let's print out the best parameters we get. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b22152f",
      "metadata": {
        "id": "5b22152f"
      },
      "outputs": [],
      "source": [
        "grids = GridSearchCV(dt_classifier, param_grid = parameters, cv = 3, return_train_score = True)\n",
        "for tag in gr_tags:\n",
        "    grids.fit(x_tr, train[tag])\n",
        "\n",
        "grids.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e25b700",
      "metadata": {
        "id": "9e25b700"
      },
      "source": [
        "Let's now re-run our training, testing, and calculating of precision and recall to calculate a new and hopefully improved average f1 score. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeb2a078",
      "metadata": {
        "id": "eeb2a078"
      },
      "outputs": [],
      "source": [
        "dt_classifier = Pipeline([('tdidf', TfidfVectorizer(stop_words = stop_words)), ('dtc', DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 2))])\n",
        "\n",
        "prec_recs = {}\n",
        "for tag in gr_tags:\n",
        "    \n",
        "    dt_classifier.fit(x_tr, train[tag])\n",
        "    prediction = dt_classifier.predict(x_te)\n",
        "    \n",
        "    precision_recall = precision_recall_fscore_support(test[tag], prediction, average = 'macro')\n",
        "    prec_recs[tag] = precision_recall\n",
        "\n",
        "sum_precision = 0\n",
        "sum_recall = 0\n",
        "\n",
        "for key in prec_recs.keys():\n",
        "    \n",
        "    sum_precision += prec_recs[key][0]\n",
        "    sum_recall += prec_recs[key][1]\n",
        "    \n",
        "mean_precision = sum_precision / len(prec_recs.keys())\n",
        "mean_recall = sum_recall / len(prec_recs.keys())\n",
        "\n",
        "average_f1 = (2 * mean_precision * mean_recall) / (mean_precision + mean_recall)\n",
        "average_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e679a6a3",
      "metadata": {
        "id": "e679a6a3"
      },
      "source": [
        "So we see a decent improvement from 0.71 --> 0.78, achieved with GridSearchCV and stop_word inclusion to optimize our model. However, we'll take a look at other models / optimizations to see if we can get a heightened score. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84a537a2",
      "metadata": {
        "id": "84a537a2"
      },
      "source": [
        "### Model 2: "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next model we'll try is a Keras Sequential() model with a couple layers. Firstly, we'll already go ahead and remove stopwords from both the quotes and tags, and append these to new columns. "
      ],
      "metadata": {
        "id": "DRIUOH-y8z-z"
      },
      "id": "DRIUOH-y8z-z"
    },
    {
      "cell_type": "code",
      "source": [
        "goodreads = goodreads[goodreads['isEmpty'] == False]\n",
        "goodreads['stop_quote'] = goodreads['quote'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "goodreads['stop_tags'] = goodreads['tags'].apply(lambda x: [z for z in x if z not in stop_words])\n",
        "\n",
        "goodreads.head()"
      ],
      "metadata": {
        "id": "lVdL9EQQZ8cO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "e220ef6c-5510-4454-b2e0-387a0dd53829"
      },
      "id": "lVdL9EQQZ8cO",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               quote  \\\n",
              "0         be yourself everyone else is already taken   \n",
              "1  im selfish impatient and a little insecure i m...   \n",
              "2  two things are infinite the universe and human...   \n",
              "3                       so many books so little time   \n",
              "4  a room without books is like a body without a ...   \n",
              "\n",
              "                                                tags  isEmpty  \\\n",
              "0  [attributed, no, source, be, yourself, gilbert...    False   \n",
              "1  [attributed, no, source, best, life, love, mis...    False   \n",
              "2  [attributed, no, source, human, nature, humor,...    False   \n",
              "3                                     [books, humor]    False   \n",
              "4      [attributed, no, source, books, simile, soul]    False   \n",
              "\n",
              "                                          stop_quote  \\\n",
              "0                        everyone else already taken   \n",
              "1  im selfish impatient little insecure make mist...   \n",
              "2  two things infinite universe human stupidity i...   \n",
              "3                             many books little time   \n",
              "4          room without books like body without soul   \n",
              "\n",
              "                                           stop_tags  \n",
              "0  [attributed, source, gilbert, perreira, honest...  \n",
              "1  [attributed, source, best, life, love, mistake...  \n",
              "2  [attributed, source, human, nature, humor, inf...  \n",
              "3                                     [books, humor]  \n",
              "4          [attributed, source, books, simile, soul]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9328cf1d-bb07-4698-aac5-98dfe507522c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "      <th>tags</th>\n",
              "      <th>isEmpty</th>\n",
              "      <th>stop_quote</th>\n",
              "      <th>stop_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>be yourself everyone else is already taken</td>\n",
              "      <td>[attributed, no, source, be, yourself, gilbert...</td>\n",
              "      <td>False</td>\n",
              "      <td>everyone else already taken</td>\n",
              "      <td>[attributed, source, gilbert, perreira, honest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im selfish impatient and a little insecure i m...</td>\n",
              "      <td>[attributed, no, source, best, life, love, mis...</td>\n",
              "      <td>False</td>\n",
              "      <td>im selfish impatient little insecure make mist...</td>\n",
              "      <td>[attributed, source, best, life, love, mistake...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>two things are infinite the universe and human...</td>\n",
              "      <td>[attributed, no, source, human, nature, humor,...</td>\n",
              "      <td>False</td>\n",
              "      <td>two things infinite universe human stupidity i...</td>\n",
              "      <td>[attributed, source, human, nature, humor, inf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>so many books so little time</td>\n",
              "      <td>[books, humor]</td>\n",
              "      <td>False</td>\n",
              "      <td>many books little time</td>\n",
              "      <td>[books, humor]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a room without books is like a body without a ...</td>\n",
              "      <td>[attributed, no, source, books, simile, soul]</td>\n",
              "      <td>False</td>\n",
              "      <td>room without books like body without soul</td>\n",
              "      <td>[attributed, source, books, simile, soul]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9328cf1d-bb07-4698-aac5-98dfe507522c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9328cf1d-bb07-4698-aac5-98dfe507522c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9328cf1d-bb07-4698-aac5-98dfe507522c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll shuffle the data using pandas sample() functions, and take only our new stop-word removed quotes and tags columns. Then we'll split training and testing data on an 80/20 split, and get validation data as half the test data.\n",
        "\n",
        "The shapes of the data are as follows:"
      ],
      "metadata": {
        "id": "1Z9QmTDJ9H55"
      },
      "id": "1Z9QmTDJ9H55"
    },
    {
      "cell_type": "code",
      "source": [
        "goodreads_sample = goodreads.sample(frac = 1)\n",
        "goodreads_sample = goodreads_sample[['stop_tags', 'stop_quote']]\n",
        "train, test = train_test_split(goodreads_sample, test_size = 0.2, shuffle = True)\n",
        "val = test.sample(frac=0.5)\n",
        "test.drop(val.index, inplace=True)\n",
        "train.shape, test.shape, val.shape"
      ],
      "metadata": {
        "id": "USBExS3qxJmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000cb08f-d788-4d91-a7a7-6424e008f802"
      },
      "id": "USBExS3qxJmd",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2002, 2), (251, 2), (250, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll encode the list of strings in the \"stop_tags\" column to shift them from just being Strings to an integer output. We'll accomplish this via keras' constant() and StringLookup() functionality. Since we have multiple tags per quote, we need to use multi-hot encoding, since it allows for multiple markers to have a 1 (reflecting presence) indicating multiple labels. "
      ],
      "metadata": {
        "id": "B4oMF7cEAqKe"
      },
      "id": "B4oMF7cEAqKe"
    },
    {
      "cell_type": "code",
      "source": [
        "terms = constant(train[\"stop_tags\"].values)\n",
        "lookup = StringLookup(output_mode = \"multi_hot\")\n",
        "lookup.adapt(terms)"
      ],
      "metadata": {
        "id": "ejX6_BOAy4AL"
      },
      "id": "ejX6_BOAy4AL",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to need some information about our quote data, so we'll quickly split them into lists and use pandas describe() methods to generate the info about max lengths, avg lengths, etc."
      ],
      "metadata": {
        "id": "ikEvwdE6A-F-"
      },
      "id": "ikEvwdE6A-F-"
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"stop_quote\"].apply(lambda x: len(x.split(\" \"))).describe()"
      ],
      "metadata": {
        "id": "nOxTfAAy5Uul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59bebc58-338c-450d-9339-34d92aab4ffe"
      },
      "id": "nOxTfAAy5Uul",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2002.000000\n",
              "mean       14.582917\n",
              "std        22.414865\n",
              "min         1.000000\n",
              "25%         6.000000\n",
              "50%         9.000000\n",
              "75%        15.000000\n",
              "max       348.000000\n",
              "Name: stop_quote, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we're going to convert our training / testing / validation data from pandas DataFrames to keras Batch Datasets, because the latter will split up the datasets into chunks of a given size, which makes feeding it into our model much easier. "
      ],
      "metadata": {
        "id": "uTiq5hxWfaey"
      },
      "id": "uTiq5hxWfaey"
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_tensors(df, batch_size = 6):\n",
        "\n",
        "    labels = constant(df[\"stop_tags\"].values)\n",
        "    label_binarized = lookup(labels).numpy()\n",
        "\n",
        "    tensor_df = Dataset.from_tensor_slices((df[\"stop_quote\"].values, label_binarized))\n",
        "    batch_df = tensor_df.batch(batch_size)\n",
        "    return batch_df\n",
        "\n",
        "train_dataset = convert_to_tensors(train)\n",
        "validation_dataset = convert_to_tensors(val)\n",
        "test_dataset = convert_to_tensors(test)"
      ],
      "metadata": {
        "id": "6NBCdZQp6HDo"
      },
      "id": "6NBCdZQp6HDo",
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKfFOMUsrOtj",
        "outputId": "3a8fd4e6-a385-4696-9fff-12d0aeb070ff"
      },
      "id": "mKfFOMUsrOtj",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 1819), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a set of our unique words in our quotes column. We'll create a blank set and append the words to it. The size is as follows:"
      ],
      "metadata": {
        "id": "Bgr3wt2eRmw5"
      },
      "id": "Bgr3wt2eRmw5"
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = set()\n",
        "\n",
        "total_words = train[\"stop_quote\"].str.lower().str.split()\n",
        "total_words.apply(vocabulary.update)\n",
        "\n",
        "num_words = len(vocabulary)\n",
        "print(num_words)"
      ],
      "metadata": {
        "id": "NAUc4TeW6eW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f15655-c0af-4cea-a1aa-42c4b76514b6"
      },
      "id": "NAUc4TeW6eW9",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have to represent our strings as vectors so that they can be fed into the model. Like our first model, we will use a TFIDF representation, conducted through Keras' TextVectorization function. We will have our maximum number of tokens set to as many unique words we have, and we will set ngrams = 2 because they will help the model understand context of related words. \n",
        "\n",
        "\n",
        "Then, we'll adapt it to our training dataset to generate the vocabulary from our quotes column. \n",
        "\n",
        "Now we can remake our datasets with our quotes converted to TFIDF-representation vectors. We do this by mapping the tensor dataframes's columns to a tfidf-representation quote and tags. "
      ],
      "metadata": {
        "id": "rDT3p--7Ygeb"
      },
      "id": "rDT3p--7Ygeb"
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vect = TextVectorization(max_tokens = num_words, ngrams = 2, output_mode = \"tf_idf\")\n",
        "tfidf_vect.adapt(train_dataset.map(lambda quote, tags: quote))\n",
        "\n",
        "train_dataset = train_dataset.map(lambda quote, tags: (tfidf_vect(quote), tags))\n",
        "validation_dataset = validation_dataset.map(lambda quote, tags: (tfidf_vect(quote), tags))\n",
        "test_dataset = test_dataset.map(lambda quote, tags: (tfidf_vect(quote), tags))"
      ],
      "metadata": {
        "id": "HCapfP8E60VO"
      },
      "id": "HCapfP8E60VO",
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll build the Keras Sequential() model with a few different layers:\n",
        "\n",
        "- Firstly, we'll include a Dropout layer. This will help combat overfitting by randomly setting some input variables to 0 for ignoring. \n",
        "\n",
        "- Next, we'll add a generic Dense layer that will take in 1000 values, and a ReLU activation function. \n",
        "\n",
        "- We'll do this again in the next layer; however, this time we'll input half of our prior layer. \n",
        "\n",
        "- Finally, we'll get our output layer with a size of how many unique tags we have. We'll use a sigmoid activation function because we are dealing with a classification problem. \n",
        "\n",
        "Compilation:\n",
        "\n",
        "For any particular given quote, they can have multiple tags. As such, we'll use a binary cross entropy loss function, since the model will attempt to predict whether or not a particular observation (Quote) belongs to any particular class of classes (Tags).\n",
        "\n",
        "We will use a baseline Adam optimizer, which ..., and we will use metrics of precision and recall to calculate an f1 score, which we want to use given the imbalance of classes. "
      ],
      "metadata": {
        "id": "0dM1g1YDrDu0"
      },
      "id": "0dM1g1YDrDu0"
    },
    {
      "cell_type": "code",
      "source": [
        "keras_model = Sequential()\n",
        "keras_model.add(Dropout(0.2))\n",
        "keras_model.add(Dense(1000, activation = 'relu'))\n",
        "keras_model.add(Dense(500, activation = 'relu'))\n",
        "keras_model.add(Dense(lookup.vocabulary_size(), activation = 'sigmoid'))\n",
        "\n",
        "loss = 'binary_crossentropy'\n",
        "opt = Adam()\n",
        "\n",
        "keras_model.compile(loss = loss, optimizer = opt, metrics = [Precision(), Recall()])\n",
        "keras_model.build((None, num_words))\n",
        "keras_model.summary()"
      ],
      "metadata": {
        "id": "G1Zq4ywP7GB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e8cb5f-2547-4c7f-8c78-fd34f3d7d628"
      },
      "id": "G1Zq4ywP7GB9",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_11 (Dropout)        (None, 6791)              0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 1000)              6792000   \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1819)              911319    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,203,819\n",
            "Trainable params: 8,203,819\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can fit the Keras model onto our training dataset, which we will do so over 5 epochs. "
      ],
      "metadata": {
        "id": "CtfLP9-zb5Em"
      },
      "id": "CtfLP9-zb5Em"
    },
    {
      "cell_type": "code",
      "source": [
        "history = keras_model.fit(train_dataset, validation_data = validation_dataset, epochs = 5)"
      ],
      "metadata": {
        "id": "utdWTtwS7WXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c8c7f4-1d93-41d8-8452-2cf16b977f2b"
      },
      "id": "utdWTtwS7WXG",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "334/334 [==============================] - 18s 51ms/step - loss: 0.0349 - precision_11: 0.0031 - recall_11: 0.0052 - val_loss: 0.0218 - val_precision_11: 0.0000e+00 - val_recall_11: 0.0000e+00\n",
            "Epoch 2/5\n",
            "334/334 [==============================] - 17s 51ms/step - loss: 0.0158 - precision_11: 0.7419 - recall_11: 0.0032 - val_loss: 0.0189 - val_precision_11: 0.0000e+00 - val_recall_11: 0.0000e+00\n",
            "Epoch 3/5\n",
            "334/334 [==============================] - 17s 50ms/step - loss: 0.0124 - precision_11: 0.8400 - recall_11: 0.0265 - val_loss: 0.0145 - val_precision_11: 0.1500 - val_recall_11: 0.0036\n",
            "Epoch 4/5\n",
            "334/334 [==============================] - 17s 50ms/step - loss: 0.0098 - precision_11: 0.8593 - recall_11: 0.0951 - val_loss: 0.0129 - val_precision_11: 0.5185 - val_recall_11: 0.0167\n",
            "Epoch 5/5\n",
            "334/334 [==============================] - 17s 50ms/step - loss: 0.0075 - precision_11: 0.8799 - recall_11: 0.2098 - val_loss: 0.0132 - val_precision_11: 0.3168 - val_recall_11: 0.0382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we'll evaluate on the test dataset and see what we get for our precision and recall. "
      ],
      "metadata": {
        "id": "n3xDqLZ9cARv"
      },
      "id": "n3xDqLZ9cARv"
    },
    {
      "cell_type": "code",
      "source": [
        "info = keras_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "yrAMk_t57Y7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de06214-8450-4100-88d1-69ca567372ea"
      },
      "id": "yrAMk_t57Y7G",
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 1s 12ms/step - loss: 0.0134 - precision_11: 0.3368 - recall_11: 0.0387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we calculate the F1 score. "
      ],
      "metadata": {
        "id": "d9wyACHqQvSM"
      },
      "id": "d9wyACHqQvSM"
    },
    {
      "cell_type": "code",
      "source": [
        "p = info[1]\n",
        "r = info[2]\n",
        "\n",
        "f1 = (2 * p * r) / (p + r)\n",
        "f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTm6rdloQvkK",
        "outputId": "9784537c-f8f4-4e3e-fc19-99ea42e33b93"
      },
      "id": "CTm6rdloQvkK",
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0694896881163711"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite a middling precision, our recall is very low, and so our F1 score is as well, since the F1 is just the harmonic mean of our two given metrics. The fraction of correct predictions that the model guessed out of the total possible is too low for us to consider this a success. "
      ],
      "metadata": {
        "id": "qZuKH2z4YIAE"
      },
      "id": "qZuKH2z4YIAE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Single-Tag Classification\n",
        "\n",
        "Given the unsuccessful nature of using a list of tags, let's try a completely different approach and see if we can make a better result, albeit from a different standpoint. \n",
        "\n",
        "Instead of trying to classify from a multilabel view, what if we just assign one tag to each quote? We saw earlier than many tags are repeated throughout the quotes, so random selection of one would simplify the problem. \n",
        "\n",
        "We'll apply this idea by using numpy's random.choice() method on each list of tags and putting that new tag in a column called 'rand_tag'. "
      ],
      "metadata": {
        "id": "Zha1rzKdBTWY"
      },
      "id": "Zha1rzKdBTWY"
    },
    {
      "cell_type": "code",
      "source": [
        "subset = goodreads[['stop_quote', 'stop_tags']]\n",
        "subset['rand_tag'] = subset['stop_tags'].apply(lambda x: np.random.choice(x))\n",
        "subset.head()"
      ],
      "metadata": {
        "id": "JsfZfIjeiDqc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c220e484-6542-4374-c516-18d80b3ad5ee"
      },
      "id": "JsfZfIjeiDqc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          stop_quote  \\\n",
              "0                        everyone else already taken   \n",
              "1  im selfish impatient little insecure make mist...   \n",
              "2  two things infinite universe human stupidity i...   \n",
              "3                             many books little time   \n",
              "4          room without books like body without soul   \n",
              "\n",
              "                                           stop_tags       rand_tag  \n",
              "0  [attributed, source, gilbert, perreira, honest...  inspirational  \n",
              "1  [attributed, source, best, life, love, mistake...        control  \n",
              "2  [attributed, source, human, nature, humor, inf...          human  \n",
              "3                                     [books, humor]          humor  \n",
              "4          [attributed, source, books, simile, soul]         source  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a01ee4d1-d0ac-4de2-ba2c-372ea29ba0e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_quote</th>\n",
              "      <th>stop_tags</th>\n",
              "      <th>rand_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>everyone else already taken</td>\n",
              "      <td>[attributed, source, gilbert, perreira, honest...</td>\n",
              "      <td>inspirational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im selfish impatient little insecure make mist...</td>\n",
              "      <td>[attributed, source, best, life, love, mistake...</td>\n",
              "      <td>control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>two things infinite universe human stupidity i...</td>\n",
              "      <td>[attributed, source, human, nature, humor, inf...</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>many books little time</td>\n",
              "      <td>[books, humor]</td>\n",
              "      <td>humor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>room without books like body without soul</td>\n",
              "      <td>[attributed, source, books, simile, soul]</td>\n",
              "      <td>source</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a01ee4d1-d0ac-4de2-ba2c-372ea29ba0e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a01ee4d1-d0ac-4de2-ba2c-372ea29ba0e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a01ee4d1-d0ac-4de2-ba2c-372ea29ba0e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll encode the tag by looping through the tags and placing them in a dictionary. If the tag exists in the dictionary, then nothing is done; however, if not, then it is added, and the number assigned is the new length of the dictionary. \n",
        "\n",
        "For example, a group of lists like:\n",
        "\n",
        "[['life', 'love', 'data']\n",
        "\n",
        "['love', 'joy', 'science']] \n",
        "\n",
        "would generate a dictionary of \n",
        "\n",
        "{'life': 1, 'love': 2, 'data': 3, 'joy': 4, 'science': 5}"
      ],
      "metadata": {
        "id": "WCvQjwfbB3O_"
      },
      "id": "WCvQjwfbB3O_"
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = {}\n",
        "\n",
        "for tag in subset.rand_tag:\n",
        "\n",
        "  if tag not in encoded.keys():\n",
        "\n",
        "    encoded[tag] = len(encoded)\n",
        "\n",
        "subset['encoded_tag'] = subset.rand_tag.map(encoded)"
      ],
      "metadata": {
        "id": "i5NwODewwuLu"
      },
      "id": "i5NwODewwuLu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll shuffle the data again and reset the index. "
      ],
      "metadata": {
        "id": "MgN9LkHBClm4"
      },
      "id": "MgN9LkHBClm4"
    },
    {
      "cell_type": "code",
      "source": [
        "subset = subset.sample(frac = 1).reset_index(drop = True)\n",
        "subset.head()"
      ],
      "metadata": {
        "id": "Ipv_1qfWxdd-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4fff0eea-e089-4e57-844d-77bfcbfee26d"
      },
      "id": "Ipv_1qfWxdd-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          stop_quote  \\\n",
              "0                      dreams touchstones characters   \n",
              "1                past beats inside like second heart   \n",
              "2  dance youre broken open dance youve torn banda...   \n",
              "3                                say weep tears evil   \n",
              "4  perhaps many causes worth dying certainly none...   \n",
              "\n",
              "                                           stop_tags    rand_tag  encoded_tag  \n",
              "0                  [characters, dreams, touchstones]  characters          816  \n",
              "1                                   [memories, past]        past          699  \n",
              "2                             [dance, inspirational]       dance          181  \n",
              "3                                   [gandalf, grief]       grief          173  \n",
              "4  [martyrdom, misattributed, albert, camus, paci...         war          357  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10ef9f4a-c27e-4c67-90bf-5ae405d24883\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_quote</th>\n",
              "      <th>stop_tags</th>\n",
              "      <th>rand_tag</th>\n",
              "      <th>encoded_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dreams touchstones characters</td>\n",
              "      <td>[characters, dreams, touchstones]</td>\n",
              "      <td>characters</td>\n",
              "      <td>816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>past beats inside like second heart</td>\n",
              "      <td>[memories, past]</td>\n",
              "      <td>past</td>\n",
              "      <td>699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dance youre broken open dance youve torn banda...</td>\n",
              "      <td>[dance, inspirational]</td>\n",
              "      <td>dance</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>say weep tears evil</td>\n",
              "      <td>[gandalf, grief]</td>\n",
              "      <td>grief</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>perhaps many causes worth dying certainly none...</td>\n",
              "      <td>[martyrdom, misattributed, albert, camus, paci...</td>\n",
              "      <td>war</td>\n",
              "      <td>357</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10ef9f4a-c27e-4c67-90bf-5ae405d24883')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10ef9f4a-c27e-4c67-90bf-5ae405d24883 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10ef9f4a-c27e-4c67-90bf-5ae405d24883');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we'll onehot encode the tags via keras' to_categorical() function. This will take a Series of integers and convert it to arrays of 1 (present) and 0s (not present). "
      ],
      "metadata": {
        "id": "P2hJcpbIDvdV"
      },
      "id": "P2hJcpbIDvdV"
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_encoded = to_categorical(subset.encoded_tag)\n",
        "onehot_encoded"
      ],
      "metadata": {
        "id": "oCPuME83ygYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3f2bd2-2092-4da5-b7f5-dcf872f498cb"
      },
      "id": "oCPuME83ygYC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to use a AutoTokenizer to help tokenize our quotes later on, as well as a pretrained BERT model. "
      ],
      "metadata": {
        "id": "yNntqD_uEJWo"
      },
      "id": "yNntqD_uEJWo"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "bert = TFBertModel.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "hIDgRG5rzT6q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "16418ddee9ab40708ce13c2c8d58f4ac",
            "0d24418d9b0e49e9bdbc8a06e060d2e3",
            "c776c8768a23404a8520f1d50a8bad76",
            "2d2a286120724ef2ad3d308d049cbedf",
            "23314bfc532b4b74b9dbe0e09791bfee",
            "a7112f06f83c4e85a8782b719037ff8a",
            "51c8642997b546998c6b19733dc67c62",
            "c1d6078a078c4d13862a9c3fff26ad59",
            "f28e69f3eb184ea7b08fbfcd6a58f21e",
            "070aed264db64fe885f772ce2283f766",
            "b4c7d38613b14c428ebbcd3e2e32c7ab",
            "1e37028eaa7d4c218471aaea0d5b904b",
            "3f3c469f121d449e899f5b75370df3c7",
            "dc6da32b047e42f68f0e3df400d7efd4",
            "e6b15af088fb4287bc35d126a07eb2e0",
            "0d25f59b83654b3ca2012730473e8503",
            "bd0977d558c1449db067c7e7ef4b23c7",
            "46bec757fd62437687f63cb0d8733a88",
            "3d67c95088ba491680bd41a2c0f161b6",
            "79958aaafeb14d019b0a1c21131d61da",
            "f171c7cc8166477487f4aa8e581c2050",
            "89a1238cc4e44eb78092f4a2adadeadc",
            "a46050624af54e6689273d4eef688284",
            "89f7a95f04b844e1939026417a0b9df7",
            "237668ec5353450fad3a84727c11f1d9",
            "12f3e7950c0f44609825fe8156ba7ad1",
            "ed14b7a1d0e949b6ae999ef7ad930c1e",
            "49716daf1b6843b19184a3de4d3a11ee",
            "24f129b0e3624cc78f33a2aac81cd065",
            "3ed3489b523a44ddac1ca5fa27524b4a",
            "86b7fa195309474a86977edaab10f9a6",
            "a5a3157659014e1cb3702cebbd16e181",
            "dd8590ea285e4e74aa63b7c7f98b5b32",
            "f2484093202247c9808d898ce836f6f1",
            "d5579ccb8adb4d2db405451548ff381a",
            "5c6a372e43614a66a474666f34157a4b",
            "92226606c6ec446380994645eae384d0",
            "eb3356dd1a0c47d691f917c2460d120f",
            "71d820663d6a4b61aefc55d7059fd5db",
            "8d1499d4e4c0406d90cc12cb5638853e",
            "e8b67f0bb25143bdb14b270ef2a3aabc",
            "9a09b16767a74f50af0110a1d3d01042",
            "35420d46a32441609a75a0bad9b59cd0",
            "d01432a14e6e41c196fb110cdb5c2bd6",
            "3d82a4285eaf41f5b99a66dc7688017d",
            "fa632c094c1b47dbb3960f1d7f046dff",
            "776e92c2fae74a5fa48d695db516e95f",
            "da7d52860916443d9a6cb3e12f0c501c",
            "99dea22423254aaf9a198f98f5082ed9",
            "66517019280943c6a73e30eff3a1e66c",
            "2394bbac14654494a0b0d000c14b9a89",
            "e8533b63f5754657a1ac56b2f997c3c1",
            "440b6ad948264bbc8aabd2d9d2a5633e",
            "e1a99d7b0cd84a8f95a6b099ca927be6",
            "08ccd87a84fc41029d606e9bbe4ba64e"
          ]
        },
        "outputId": "07cd8665-40b2-4eb9-b636-77e3fc1de154"
      },
      "id": "hIDgRG5rzT6q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16418ddee9ab40708ce13c2c8d58f4ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e37028eaa7d4c218471aaea0d5b904b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a46050624af54e6689273d4eef688284"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2484093202247c9808d898ce836f6f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d82a4285eaf41f5b99a66dc7688017d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll split into training and testing data, with a split of 80/20 on our stop_quote and encoded_tag columns. \n",
        "\n",
        "We'll again find out information to inform our model via pandas describe() functionality. "
      ],
      "metadata": {
        "id": "GgKKCKLCGf5Y"
      },
      "id": "GgKKCKLCGf5Y"
    },
    {
      "cell_type": "code",
      "source": [
        "data = subset[['stop_quote', 'encoded_tag']]\n",
        "train, test = train_test_split(data, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "ulYA-F6xz0a8"
      },
      "id": "ulYA-F6xz0a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subset[\"stop_quote\"].apply(lambda x: len(x.split(\" \"))).describe()"
      ],
      "metadata": {
        "id": "jvftf0Xg0iSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2519eed-837c-47f1-d67c-19e27a160d00"
      },
      "id": "jvftf0Xg0iSG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2475.000000\n",
              "mean       14.407677\n",
              "std        21.539474\n",
              "min         1.000000\n",
              "25%         6.000000\n",
              "50%         9.000000\n",
              "75%        15.000000\n",
              "max       348.000000\n",
              "Name: stop_quote, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll develop our x values from our training and testing datasets and tokenize them via the tokenizer initialization. \n",
        "\n",
        "We have several parameters to use:\n",
        "- max_length is based off the information we saw earlier. This informs why we have truncation = True\n",
        "- return_attention_mask = True. This informs the model not to pay attention to the special padding tokens when it reads the sentence. "
      ],
      "metadata": {
        "id": "FjsCi3thHJB_"
      },
      "id": "FjsCi3thHJB_"
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = tokenizer(text = train['stop_quote'].tolist(), max_length = 9, truncation = True, padding = True, return_tensors = 'tf', return_token_type_ids = False, return_attention_mask = True)\n",
        "x_test = tokenizer(text = test['stop_quote'].tolist(), max_length = 9, truncation = True, padding = True, return_tensors = 'tf', return_token_type_ids = False, return_attention_mask = True)\n"
      ],
      "metadata": {
        "id": "y2QI43-m0LlZ"
      },
      "id": "y2QI43-m0LlZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can generate our y values from our training and testing datasets."
      ],
      "metadata": {
        "id": "A6yj7zV4KNQa"
      },
      "id": "A6yj7zV4KNQa"
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train['encoded_tag']\n",
        "y_test = test['encoded_tag']"
      ],
      "metadata": {
        "id": "Ws5Rbsnv0nhX"
      },
      "id": "Ws5Rbsnv0nhX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we begin building our model. \n",
        "\n",
        "Firstly, we need to build 2 input layers – one for our input tokens, and one for attention masks. The first is a list of tokens that we are feeding into our model, and the second is a list of indices that the model should ignore (i.e., special tokens)\n",
        "\n",
        "Next, we'll input these into a BERT model for embedding. \n",
        "\n",
        "Now, we have to build the actual Keras model. \n",
        "\n",
        "1. Firstly, we'll use a GlobalMaxPool of 1 Dimension as the first layer. This will return the maximum value of the input ids (notwithstanding the indexes for the special ids). \n",
        "\n",
        "2. Next, we'll include a Dense layer of size 256, and we'll use a ReLU activation function. ReLU will take the input variable, and return the same variable if it is positive, and 0 otherwise. We choose to use ReLU here because the function is simple, and so the model will learn more quickly. Furthermore, it is generally applicable for many kinds of tasks.  \n",
        "\n",
        "3. Next, we will have a Dropout layer. The layer randomly shifts some values to 0 at a rate of 0.1. This will be activated in the last line where we set the layer as trainable, so the values are preserved, and not dropped, when they are turned to 0. We use a Dropout layer to prevent overfitting, since the size of the dataset is relatively small for a whole Keras NN.\n",
        "\n",
        "4. Next, we'll have another Dense layer, this time of size 64. We use another ReLU activation function. \n",
        "\n",
        "5. Finally, we'll use a single-value Dense layer to predict the y value with a sigmoid activation function. Sigmoid functions work well in cases of classification, which we are aiming to do here, so we want to use it in the final layer when the model is generating the final values of prediction. \n",
        "\n"
      ],
      "metadata": {
        "id": "daMiuhhxLNlG"
      },
      "id": "daMiuhhxLNlG"
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 9\n",
        "ids = Input(shape = (max_len,), dtype = tf.int32, name = \"ids\")\n",
        "masks = Input(shape = (max_len,), dtype = tf.int32, name = \"masks\")\n",
        "\n",
        "bert_embedded = bert(ids, attention_mask = masks)[0]\n",
        "maxpool = tf.keras.layers.GlobalMaxPool1D()(bert_embedded)\n",
        "dense_1 = Dense(256, activation = 'relu')(maxpool)\n",
        "dropout = tf.keras.layers.Dropout(0.1)(dense_1)\n",
        "dense_2 = Dense(64, activation = 'relu')(dropout)\n",
        "prediction = Dense(1, activation = 'sigmoid')(dense_2)\n",
        "\n",
        "\n",
        "model = tf.keras.Model(inputs=[ids, masks], outputs = prediction)\n",
        "model.layers[2].trainable = True"
      ],
      "metadata": {
        "id": "pC4f2C0909QP"
      },
      "id": "pC4f2C0909QP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's print out the summary of the model"
      ],
      "metadata": {
        "id": "ydoFxOt7mjwo"
      },
      "id": "ydoFxOt7mjwo"
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "tHo5G6OV6OXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e7854f-6a2d-49c1-ab8c-c499ae1d0905"
      },
      "id": "tHo5G6OV6OXb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " ids (InputLayer)               [(None, 9)]          0           []                               \n",
            "                                                                                                  \n",
            " masks (InputLayer)             [(None, 9)]          0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['ids[0][0]',                    \n",
            "                                thPoolingAndCrossAt               'masks[0][0]']                  \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 9, 7                                               \n",
            "                                68),                                                              \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 256)          196864      ['global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 256)          0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 64)           16448       ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            65          ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,523,649\n",
            "Trainable params: 108,523,649\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have to compile the model, with an optimizer and loss function. \n",
        "\n",
        "For our optimizer, we will use an Adam optimizer, which is an optimizer based off of stochastic gradient descent. We choose to use this optimizer because ...\n",
        "\n",
        "Next, for our loss, we will use Categorical Crossentropy, because we have data where each value could have one out of any number of tags. Therefore, this loss function will best suit our model. From [Google](https://developers.google.com/machine-learning/glossary/#logits), logits are \"the vector of raw (non-normalized) predictions that a classification model generates\" which is our y-value so the from_logits parameter must be True.\n",
        "\n",
        "Now, we'll run compile() with our generated optimizer and loss functions. We'll select Precision and Recall as our returned metrics so that we can calculate an F1 score. F1 scores work best for imbalanced classes which we would have here. "
      ],
      "metadata": {
        "id": "NhFDd1VZ4Dta"
      },
      "id": "NhFDd1VZ4Dta"
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate = 5e-05, epsilon = 1e-08, decay = 0.01, clipnorm=1.0)\n",
        "loss = CategoricalCrossentropy(from_logits = True)\n",
        "\n",
        "model.compile(optimizer = adam, loss = loss, metrics = [Precision(), Recall()])"
      ],
      "metadata": {
        "id": "RTY_BW6g1MaN"
      },
      "id": "RTY_BW6g1MaN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, we have to make a dictionary of our 2 input values since we have to pass in the 'input_ids' and the 'attention_mask' data points. Next, we'll also preemptively set our validation data by pulling it from our test dataset. \n",
        "\n",
        "Then we'll fit the model to our x, y_train, val data over 5 epochs with a batch_size of 32. "
      ],
      "metadata": {
        "id": "gE2UOCxj-B6e"
      },
      "id": "gE2UOCxj-B6e"
    },
    {
      "cell_type": "code",
      "source": [
        "x = {'ids': x_train['input_ids'], 'masks': x_train['attention_mask']}\n",
        "val = ({'ids': x_test['input_ids'], 'masks': x_test['attention_mask']}, y_test)\n",
        "\n",
        "train_history = model.fit(x = x, y = y_train, validation_data = val, epochs = 5)"
      ],
      "metadata": {
        "id": "ouUZpySm1QbH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d957af0-6b53-4a93-a44f-45c2629befab"
      },
      "id": "ouUZpySm1QbH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "62/62 [==============================] - 204s 3s/step - loss: 0.0000e+00 - precision_1: 0.9433 - recall_1: 0.9888 - val_loss: 0.0000e+00 - val_precision_1: 0.9596 - val_recall_1: 1.0000\n",
            "Epoch 2/5\n",
            "62/62 [==============================] - 159s 3s/step - loss: 0.0000e+00 - precision_1: 0.9434 - recall_1: 1.0000 - val_loss: 0.0000e+00 - val_precision_1: 0.9596 - val_recall_1: 1.0000\n",
            "Epoch 3/5\n",
            "62/62 [==============================] - 162s 3s/step - loss: 0.0000e+00 - precision_1: 0.9434 - recall_1: 1.0000 - val_loss: 0.0000e+00 - val_precision_1: 0.9596 - val_recall_1: 1.0000\n",
            "Epoch 4/5\n",
            "62/62 [==============================] - 159s 3s/step - loss: 0.0000e+00 - precision_1: 0.9434 - recall_1: 1.0000 - val_loss: 0.0000e+00 - val_precision_1: 0.9596 - val_recall_1: 1.0000\n",
            "Epoch 5/5\n",
            "62/62 [==============================] - 162s 3s/step - loss: 0.0000e+00 - precision_1: 0.9434 - recall_1: 1.0000 - val_loss: 0.0000e+00 - val_precision_1: 0.9596 - val_recall_1: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the model is fitted, we'll run it on our testing data. "
      ],
      "metadata": {
        "id": "cWveimYjBgE9"
      },
      "id": "cWveimYjBgE9"
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = {'ids':x_test['input_ids'],'masks':x_test['attention_mask']}\n",
        "\n",
        "test_info = model.evaluate(test_x, y_test)"
      ],
      "metadata": {
        "id": "6BRdnWkC9j_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58873973-e98c-4fba-9dc1-b85ffb81eb73"
      },
      "id": "6BRdnWkC9j_I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 10s 649ms/step - loss: 0.0000e+00 - precision_1: 0.9596 - recall_1: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can finally calculate our final F1 score, and we see the major improvement with this model that we achieved. "
      ],
      "metadata": {
        "id": "s5UCiEikOBIT"
      },
      "id": "s5UCiEikOBIT"
    },
    {
      "cell_type": "code",
      "source": [
        "p = test_info[1]\n",
        "r = test_info[2]\n",
        "\n",
        "f1_score = (2 * p * r) / (p + r)\n",
        "f1_score"
      ],
      "metadata": {
        "id": "4JUI0XCV1TWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e43e9a-8b43-454a-dbf7-095d45994414"
      },
      "id": "4JUI0XCV1TWW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9793814530198031"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see a much improved metric of success, proving that our model is a success. "
      ],
      "metadata": {
        "id": "051xPqYeD4an"
      },
      "id": "051xPqYeD4an"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Copy of Project Tester.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16418ddee9ab40708ce13c2c8d58f4ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d24418d9b0e49e9bdbc8a06e060d2e3",
              "IPY_MODEL_c776c8768a23404a8520f1d50a8bad76",
              "IPY_MODEL_2d2a286120724ef2ad3d308d049cbedf"
            ],
            "layout": "IPY_MODEL_23314bfc532b4b74b9dbe0e09791bfee"
          }
        },
        "0d24418d9b0e49e9bdbc8a06e060d2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7112f06f83c4e85a8782b719037ff8a",
            "placeholder": "​",
            "style": "IPY_MODEL_51c8642997b546998c6b19733dc67c62",
            "value": "Downloading: 100%"
          }
        },
        "c776c8768a23404a8520f1d50a8bad76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d6078a078c4d13862a9c3fff26ad59",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f28e69f3eb184ea7b08fbfcd6a58f21e",
            "value": 29
          }
        },
        "2d2a286120724ef2ad3d308d049cbedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_070aed264db64fe885f772ce2283f766",
            "placeholder": "​",
            "style": "IPY_MODEL_b4c7d38613b14c428ebbcd3e2e32c7ab",
            "value": " 29.0/29.0 [00:00&lt;00:00, 775B/s]"
          }
        },
        "23314bfc532b4b74b9dbe0e09791bfee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7112f06f83c4e85a8782b719037ff8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c8642997b546998c6b19733dc67c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1d6078a078c4d13862a9c3fff26ad59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f28e69f3eb184ea7b08fbfcd6a58f21e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "070aed264db64fe885f772ce2283f766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4c7d38613b14c428ebbcd3e2e32c7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e37028eaa7d4c218471aaea0d5b904b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f3c469f121d449e899f5b75370df3c7",
              "IPY_MODEL_dc6da32b047e42f68f0e3df400d7efd4",
              "IPY_MODEL_e6b15af088fb4287bc35d126a07eb2e0"
            ],
            "layout": "IPY_MODEL_0d25f59b83654b3ca2012730473e8503"
          }
        },
        "3f3c469f121d449e899f5b75370df3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd0977d558c1449db067c7e7ef4b23c7",
            "placeholder": "​",
            "style": "IPY_MODEL_46bec757fd62437687f63cb0d8733a88",
            "value": "Downloading: 100%"
          }
        },
        "dc6da32b047e42f68f0e3df400d7efd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d67c95088ba491680bd41a2c0f161b6",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79958aaafeb14d019b0a1c21131d61da",
            "value": 570
          }
        },
        "e6b15af088fb4287bc35d126a07eb2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f171c7cc8166477487f4aa8e581c2050",
            "placeholder": "​",
            "style": "IPY_MODEL_89a1238cc4e44eb78092f4a2adadeadc",
            "value": " 570/570 [00:00&lt;00:00, 14.2kB/s]"
          }
        },
        "0d25f59b83654b3ca2012730473e8503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0977d558c1449db067c7e7ef4b23c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46bec757fd62437687f63cb0d8733a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d67c95088ba491680bd41a2c0f161b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79958aaafeb14d019b0a1c21131d61da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f171c7cc8166477487f4aa8e581c2050": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89a1238cc4e44eb78092f4a2adadeadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a46050624af54e6689273d4eef688284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89f7a95f04b844e1939026417a0b9df7",
              "IPY_MODEL_237668ec5353450fad3a84727c11f1d9",
              "IPY_MODEL_12f3e7950c0f44609825fe8156ba7ad1"
            ],
            "layout": "IPY_MODEL_ed14b7a1d0e949b6ae999ef7ad930c1e"
          }
        },
        "89f7a95f04b844e1939026417a0b9df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49716daf1b6843b19184a3de4d3a11ee",
            "placeholder": "​",
            "style": "IPY_MODEL_24f129b0e3624cc78f33a2aac81cd065",
            "value": "Downloading: 100%"
          }
        },
        "237668ec5353450fad3a84727c11f1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ed3489b523a44ddac1ca5fa27524b4a",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86b7fa195309474a86977edaab10f9a6",
            "value": 213450
          }
        },
        "12f3e7950c0f44609825fe8156ba7ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5a3157659014e1cb3702cebbd16e181",
            "placeholder": "​",
            "style": "IPY_MODEL_dd8590ea285e4e74aa63b7c7f98b5b32",
            "value": " 208k/208k [00:00&lt;00:00, 631kB/s]"
          }
        },
        "ed14b7a1d0e949b6ae999ef7ad930c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49716daf1b6843b19184a3de4d3a11ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24f129b0e3624cc78f33a2aac81cd065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ed3489b523a44ddac1ca5fa27524b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b7fa195309474a86977edaab10f9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5a3157659014e1cb3702cebbd16e181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd8590ea285e4e74aa63b7c7f98b5b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2484093202247c9808d898ce836f6f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5579ccb8adb4d2db405451548ff381a",
              "IPY_MODEL_5c6a372e43614a66a474666f34157a4b",
              "IPY_MODEL_92226606c6ec446380994645eae384d0"
            ],
            "layout": "IPY_MODEL_eb3356dd1a0c47d691f917c2460d120f"
          }
        },
        "d5579ccb8adb4d2db405451548ff381a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71d820663d6a4b61aefc55d7059fd5db",
            "placeholder": "​",
            "style": "IPY_MODEL_8d1499d4e4c0406d90cc12cb5638853e",
            "value": "Downloading: 100%"
          }
        },
        "5c6a372e43614a66a474666f34157a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8b67f0bb25143bdb14b270ef2a3aabc",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a09b16767a74f50af0110a1d3d01042",
            "value": 435797
          }
        },
        "92226606c6ec446380994645eae384d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35420d46a32441609a75a0bad9b59cd0",
            "placeholder": "​",
            "style": "IPY_MODEL_d01432a14e6e41c196fb110cdb5c2bd6",
            "value": " 426k/426k [00:00&lt;00:00, 606kB/s]"
          }
        },
        "eb3356dd1a0c47d691f917c2460d120f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71d820663d6a4b61aefc55d7059fd5db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d1499d4e4c0406d90cc12cb5638853e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8b67f0bb25143bdb14b270ef2a3aabc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a09b16767a74f50af0110a1d3d01042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35420d46a32441609a75a0bad9b59cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d01432a14e6e41c196fb110cdb5c2bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d82a4285eaf41f5b99a66dc7688017d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa632c094c1b47dbb3960f1d7f046dff",
              "IPY_MODEL_776e92c2fae74a5fa48d695db516e95f",
              "IPY_MODEL_da7d52860916443d9a6cb3e12f0c501c"
            ],
            "layout": "IPY_MODEL_99dea22423254aaf9a198f98f5082ed9"
          }
        },
        "fa632c094c1b47dbb3960f1d7f046dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66517019280943c6a73e30eff3a1e66c",
            "placeholder": "​",
            "style": "IPY_MODEL_2394bbac14654494a0b0d000c14b9a89",
            "value": "Downloading: 100%"
          }
        },
        "776e92c2fae74a5fa48d695db516e95f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8533b63f5754657a1ac56b2f997c3c1",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_440b6ad948264bbc8aabd2d9d2a5633e",
            "value": 526681800
          }
        },
        "da7d52860916443d9a6cb3e12f0c501c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a99d7b0cd84a8f95a6b099ca927be6",
            "placeholder": "​",
            "style": "IPY_MODEL_08ccd87a84fc41029d606e9bbe4ba64e",
            "value": " 502M/502M [00:12&lt;00:00, 36.7MB/s]"
          }
        },
        "99dea22423254aaf9a198f98f5082ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66517019280943c6a73e30eff3a1e66c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2394bbac14654494a0b0d000c14b9a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8533b63f5754657a1ac56b2f997c3c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "440b6ad948264bbc8aabd2d9d2a5633e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1a99d7b0cd84a8f95a6b099ca927be6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08ccd87a84fc41029d606e9bbe4ba64e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}