{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gprasad125/lign167_finalproject/blob/main/Copy_of_Project_Tester.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f7ef64e",
      "metadata": {
        "id": "5f7ef64e"
      },
      "source": [
        "# Using Multiclass Text Classification to Analyze Famous Quotes \n",
        "\n",
        "#### Gokul Prasad & Hoang Nguyen \n",
        "#### LIGN 167, Winter 2022"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8998fd17",
      "metadata": {
        "id": "8998fd17"
      },
      "source": [
        "In this project, we'll aim to classify a variety of quotes with tags that refer to certain themes or elements specific to that particular quote. \n",
        "\n",
        "For example, Albert Einstein's quote “Life is like riding a bicycle. To keep your balance, you must keep moving.” would have tags like \"life\" or \"simile\" because it contains thematic elements about life, and contains a simile. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1773b1c2",
      "metadata": {
        "id": "1773b1c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ef5a46-00fe-41ac-9fdc-d10cecd1a32d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Scraping\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time \n",
        "\n",
        "# Data manipulation / cleaning / visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim as gm\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "import re \n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# Sklearn modeling\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "from keras.metrics import Precision, Recall\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2b1c8b6",
      "metadata": {
        "id": "f2b1c8b6"
      },
      "source": [
        "# Scraping and Cleaning the Data "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5efa41f",
      "metadata": {
        "id": "f5efa41f"
      },
      "source": [
        "We'll be sourcing our data from http://quotes.toscrape.com. This is a website containing 11 pages worth of quotes, each of them classified with a few tags. \n",
        "\n",
        "Firstly, we'll loop through the pages, and scrape the website HTML data with BeautifulSoup. Then, we'll use lambda functions to pull author data, quote data, and tag data. We'll put each of these into lists, and then create a pandas DataFrame to hold all our data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9738cafb",
      "metadata": {
        "id": "9738cafb"
      },
      "outputs": [],
      "source": [
        "goodreads_quotes = []\n",
        "goodreads_tags = []\n",
        "\n",
        "for i in range(1, 101):\n",
        "\n",
        "  url = 'https://www.goodreads.com/quotes?page={}'.format(i)\n",
        "\n",
        "  time.sleep(5)\n",
        "  scrape = requests.get(url)\n",
        "  parsed = BeautifulSoup(scrape.content, 'html.parser')\n",
        "\n",
        "  elements_quotes = parsed.find_all('div', class_ = \"quoteText\")\n",
        "  \n",
        "  quotes = [x.text.strip() for x in elements_quotes]\n",
        "  tags = parsed.find_all(class_ = 'quoteFooter')\n",
        "\n",
        "  goodreads_quotes += quotes\n",
        "  goodreads_tags += tags"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'quote':goodreads_quotes, 'tags':goodreads_tags}\n",
        "goodreads = pd.DataFrame(data)\n",
        "goodreads.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jZMT3V2z8r-u",
        "outputId": "f330da57-d76b-4a47-effa-ce44ab1d88e2"
      },
      "id": "jZMT3V2z8r-u",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-34d318cb-b9e7-4fc7-baba-833440c31f3b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Be yourself; everyone else is already taken.”...</td>\n",
              "      <td>[\\n, [\\n     tags:\\n       , [attributed-no-so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“I'm selfish, impatient and a little insecure....</td>\n",
              "      <td>[\\n, [\\n     tags:\\n       , [attributed-no-so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“Two things are infinite: the universe and hum...</td>\n",
              "      <td>[\\n, [\\n     tags:\\n       , [attributed-no-so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“So many books, so little time.”\\n    ―\\n  \\n ...</td>\n",
              "      <td>[\\n, [\\n     tags:\\n       , [books], ,\\n     ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“A room without books is like a body without a...</td>\n",
              "      <td>[\\n, [\\n     tags:\\n       , [attributed-no-so...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34d318cb-b9e7-4fc7-baba-833440c31f3b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34d318cb-b9e7-4fc7-baba-833440c31f3b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34d318cb-b9e7-4fc7-baba-833440c31f3b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               quote  \\\n",
              "0  “Be yourself; everyone else is already taken.”...   \n",
              "1  “I'm selfish, impatient and a little insecure....   \n",
              "2  “Two things are infinite: the universe and hum...   \n",
              "3  “So many books, so little time.”\\n    ―\\n  \\n ...   \n",
              "4  “A room without books is like a body without a...   \n",
              "\n",
              "                                                tags  \n",
              "0  [\\n, [\\n     tags:\\n       , [attributed-no-so...  \n",
              "1  [\\n, [\\n     tags:\\n       , [attributed-no-so...  \n",
              "2  [\\n, [\\n     tags:\\n       , [attributed-no-so...  \n",
              "3  [\\n, [\\n     tags:\\n       , [books], ,\\n     ...  \n",
              "4  [\\n, [\\n     tags:\\n       , [attributed-no-so...  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "289aba52",
      "metadata": {
        "id": "289aba52"
      },
      "source": [
        "As we can see, our dataset contains some pretty messy strings in all 3 columns. We'll need to process the data to make sure it's usable for our modeling later on. \n",
        "\n",
        "For quotes, we'll first make all characters lowercase, and then use regex functionality to substitute any non alphanumeric / whitespace character with a blank string. \n",
        "\n",
        "For example, if we input a quote like \"I love. LIGN 167!!?\" we would receive an output of \"i love lign 167\". We'll apply this to our Author and Quote columns to clean them up and make them much more simplified strings. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6bbad6f0",
      "metadata": {
        "id": "6bbad6f0"
      },
      "outputs": [],
      "source": [
        "def quotes_cleaning(text):\n",
        "    \n",
        "    text = text.lower()\n",
        "    \n",
        "    text = re.sub('[^A-Za-z0-9\\s]', '', text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "def tags_cleaning(text):\n",
        "    \n",
        "    text = re.sub('[\\[ \\]]', ' ', str(text))\n",
        "    text = re.sub('[^\\w]', ' ', text)\n",
        "    text = re.sub('[\\s]', ' ', text)\n",
        "    text = re.sub('[0-9]', ' ', text)\n",
        "    \n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    return text.split(' ')\n",
        "\n",
        "def remove_author(quote):\n",
        "\n",
        "  if quote[0] == '“':\n",
        "\n",
        "    end_of_quote = quote.index('”')\n",
        "    quote = quote[1:end_of_quote]\n",
        "\n",
        "  return quote\n",
        "\n",
        "def bs_to_list(tags):\n",
        "\n",
        "  if type(tags) != list:\n",
        "\n",
        "    tags = tags.find_all('a')\n",
        "  \n",
        "    tag_strs = []\n",
        "    for tag in tags[:-1]:\n",
        "\n",
        "      tag = str(tag)\n",
        "      start_idx = tag.index('\">')\n",
        "      end_idx = tag.index('</')\n",
        "      tag = tag[start_idx + 2:end_idx]\n",
        "      tag_strs.append(tag)\n",
        "\n",
        "    tags = tag_strs\n",
        "\n",
        "  return tags"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86a10b2c",
      "metadata": {
        "id": "86a10b2c"
      },
      "source": [
        "For the tags, we have to a slightly more complicated function since the data is tucked into lists. Firstly, we'll make it a string, and use regex to remove the surrounding brackets, remove non-word characters, and replace all multi-whitespaces with a single space. We'll then render the string as a list again, and return the list. \n",
        "\n",
        "For example, if we input a list like [deep?, wonderous.., love-happy], we would get an output of [deep, wonderous, love, happy]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7baedccc",
      "metadata": {
        "id": "7baedccc"
      },
      "outputs": [],
      "source": [
        "goodreads['quote'] = goodreads['quote'].apply(remove_author)\n",
        "goodreads['quote'] = goodreads['quote'].apply(quotes_cleaning)\n",
        "goodreads['tags'] = goodreads['tags'].apply(bs_to_list)\n",
        "goodreads['tags'] = goodreads['tags'].apply(tags_cleaning)\n",
        "\n",
        "isEmpty = goodreads['tags'].apply(lambda x: '' in x)\n",
        "goodreads['isEmpty'] = isEmpty"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55f4e5cf",
      "metadata": {
        "id": "55f4e5cf"
      },
      "source": [
        "Now, having cleaned the dataset more fully, we can see the impact on our data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "21f6be24",
      "metadata": {
        "id": "21f6be24",
        "outputId": "38607441-f41e-477b-c24e-b7fd40c5e527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0d3a8089-6d59-4e62-9758-581aff9f92d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "      <th>tags</th>\n",
              "      <th>isEmpty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>be yourself everyone else is already taken</td>\n",
              "      <td>[attributed, no, source, be, yourself, gilbert...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im selfish impatient and a little insecure i m...</td>\n",
              "      <td>[attributed, no, source, best, life, love, mis...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>two things are infinite the universe and human...</td>\n",
              "      <td>[attributed, no, source, human, nature, humor,...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>so many books so little time</td>\n",
              "      <td>[books, humor]</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d3a8089-6d59-4e62-9758-581aff9f92d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d3a8089-6d59-4e62-9758-581aff9f92d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d3a8089-6d59-4e62-9758-581aff9f92d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               quote  \\\n",
              "0         be yourself everyone else is already taken   \n",
              "1  im selfish impatient and a little insecure i m...   \n",
              "2  two things are infinite the universe and human...   \n",
              "3                       so many books so little time   \n",
              "\n",
              "                                                tags  isEmpty  \n",
              "0  [attributed, no, source, be, yourself, gilbert...    False  \n",
              "1  [attributed, no, source, best, life, love, mis...    False  \n",
              "2  [attributed, no, source, human, nature, humor,...    False  \n",
              "3                                     [books, humor]    False  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "goodreads.head(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "982252e6",
      "metadata": {
        "id": "982252e6"
      },
      "source": [
        "# Reshaping Data for Modeling "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce5b9174",
      "metadata": {
        "id": "ce5b9174"
      },
      "source": [
        "Now, while the data is cleaned, we can't really model accurately when our tags are all in a list. Inputting them into our sklearn Pipelines later would not work as we would want, so we have to find a way to reshape the dataframe. Firstly, we'll need to collect the minimum and maximum amount of tags, which we do as follows. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "708238d7",
      "metadata": {
        "scrolled": true,
        "id": "708238d7",
        "outputId": "21fe5ffd-ffd4-456e-d977-fb1cff3ecc8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "max_tags = goodreads['tags'].apply(lambda x: len(x)).max()\n",
        "max_tags"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12fc3047",
      "metadata": {
        "id": "12fc3047"
      },
      "source": [
        "So we see that the maximum amount of tags a quote could have would be 11 tags. So, let's generate a function that will make each list of tags equivalent by adding the necessary number of None values to make it to a list of length 11. \n",
        "\n",
        "For example, an input of [life, duck, nature] would yield [life, duck, nature, None, None, None, None, None, None, None, None]. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "7cf95757",
      "metadata": {
        "id": "7cf95757"
      },
      "outputs": [],
      "source": [
        "def pad(tags):\n",
        "\n",
        "  needed = 48 - len(tags)\n",
        "  tags = tags + ([None] * needed)\n",
        "\n",
        "  return tags"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f200c1a6",
      "metadata": {
        "id": "f200c1a6"
      },
      "source": [
        "Now we can apply that function to our Tags column, and use pandas get_dummies() functionality to reshape our dataframe to where each tag is a column, and the column contains 1s or 0s, reflecting whether or not a particular tag is in the quote belonging to that row. \n",
        "\n",
        "Unfortunately, pd.get_dummies() will create some duplicates so we'll groupby and sum to combine the duplicate tag columns. \n",
        "\n",
        "We then combine this dataframe with our original dataframe, and drop our tags columns. We can see the finished result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "aa43dfb7",
      "metadata": {
        "scrolled": true,
        "id": "aa43dfb7",
        "outputId": "28fc2619-d641-430d-c7c8-e24f841de558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ab0b3d66-3a20-4aad-9956-aa3c938ed69a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "      <th>tags_</th>\n",
              "      <th>tags_a</th>\n",
              "      <th>tags_abbey</th>\n",
              "      <th>tags_abe</th>\n",
              "      <th>tags_abilities</th>\n",
              "      <th>tags_abraham</th>\n",
              "      <th>tags_absence</th>\n",
              "      <th>tags_absurdities</th>\n",
              "      <th>tags_abundance</th>\n",
              "      <th>...</th>\n",
              "      <th>tags_youth</th>\n",
              "      <th>tags_youthfulness</th>\n",
              "      <th>tags_zarek</th>\n",
              "      <th>tags_zen</th>\n",
              "      <th>tags_zeus</th>\n",
              "      <th>tags_zoe</th>\n",
              "      <th>tags_zombies</th>\n",
              "      <th>tags_zone</th>\n",
              "      <th>tags_zsadist</th>\n",
              "      <th>tags_حب</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>be yourself everyone else is already taken</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im selfish impatient and a little insecure i m...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>two things are infinite the universe and human...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>so many books so little time</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a room without books is like a body without a ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2115 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab0b3d66-3a20-4aad-9956-aa3c938ed69a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab0b3d66-3a20-4aad-9956-aa3c938ed69a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab0b3d66-3a20-4aad-9956-aa3c938ed69a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               quote  tags_  tags_a  \\\n",
              "0         be yourself everyone else is already taken      0       0   \n",
              "1  im selfish impatient and a little insecure i m...      0       0   \n",
              "2  two things are infinite the universe and human...      0       0   \n",
              "3                       so many books so little time      0       0   \n",
              "4  a room without books is like a body without a ...      0       0   \n",
              "\n",
              "   tags_abbey  tags_abe  tags_abilities  tags_abraham  tags_absence  \\\n",
              "0           0         0               0             0             0   \n",
              "1           0         0               0             0             0   \n",
              "2           0         0               0             0             0   \n",
              "3           0         0               0             0             0   \n",
              "4           0         0               0             0             0   \n",
              "\n",
              "   tags_absurdities  tags_abundance  ...  tags_youth  tags_youthfulness  \\\n",
              "0                 0               0  ...           0                  0   \n",
              "1                 0               0  ...           0                  0   \n",
              "2                 0               0  ...           0                  0   \n",
              "3                 0               0  ...           0                  0   \n",
              "4                 0               0  ...           0                  0   \n",
              "\n",
              "   tags_zarek  tags_zen  tags_zeus  tags_zoe  tags_zombies  tags_zone  \\\n",
              "0           0         0          0         0             0          0   \n",
              "1           0         0          0         0             0          0   \n",
              "2           0         0          0         0             0          0   \n",
              "3           0         0          0         0             0          0   \n",
              "4           0         0          0         0             0          0   \n",
              "\n",
              "   tags_zsadist  tags_حب  \n",
              "0             0        0  \n",
              "1             0        0  \n",
              "2             0        0  \n",
              "3             0        0  \n",
              "4             0        0  \n",
              "\n",
              "[5 rows x 2115 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "gr_tags = pd.DataFrame(goodreads['tags'].apply(pad).tolist())\n",
        "gr_tags_oh = pd.get_dummies(gr_tags, prefix = 'tags')\n",
        "gr_tags_oh = gr_tags_oh.groupby(gr_tags_oh.columns, axis = 1).sum()\n",
        "reshaped_gr = pd.concat([goodreads, gr_tags_oh], axis = 1).drop(columns = ['isEmpty', 'tags'])\n",
        "reshaped_gr.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45b11d4a",
      "metadata": {
        "id": "45b11d4a"
      },
      "source": [
        "We can see the distribution of tags as below. 31% of our quotes only have 1 tag, while only 1% have the maximum tags possible. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "b538dc55",
      "metadata": {
        "id": "b538dc55",
        "outputId": "8748169c-0e56-4c88-9f2d-6d8d6aae4070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.001315\n",
              "1       0.001128\n",
              "2       0.001034\n",
              "3       0.000188\n",
              "4       0.000564\n",
              "          ...   \n",
              "2995    0.000376\n",
              "2996    0.000564\n",
              "2997    0.000094\n",
              "2998    0.000470\n",
              "2999    0.000376\n",
              "Length: 3000, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cnts = reshaped_gr.iloc[:, 1:].sum(axis = 1)\n",
        "cnts.hist()\n",
        "cnts / cnts.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbd0454d",
      "metadata": {
        "id": "cbd0454d"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f709dcc",
      "metadata": {
        "id": "6f709dcc"
      },
      "source": [
        "Now, we can begin our modeling. \n",
        "\n",
        "Firstly, we'll get a list of all of our tags. We'll do this by taking all columns besides \"Author\" and \"Quote\"\n",
        "\n",
        "Next, we'll use sklearn's train_test_split() function to split our dataset into a training and testing set. We'll split so that our test set is 33% of our dataset size. As we have 100 rows into our data, then we'll have a training set of 67 rows and testing size of 33 rows. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2adcc28",
      "metadata": {
        "id": "a2adcc28",
        "outputId": "368836e0-13a8-43e1-8bfc-638f9a300157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2250,)\n",
            "(750,)\n"
          ]
        }
      ],
      "source": [
        "gr_tags = reshaped_gr.columns[1:]\n",
        "\n",
        "train, test = train_test_split(reshaped_gr, test_size = 0.25, random_state = 42)\n",
        "\n",
        "x_tr = train.quote\n",
        "x_te = test.quote\n",
        "\n",
        "print(x_tr.shape)\n",
        "print(x_te.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42696382",
      "metadata": {
        "id": "42696382"
      },
      "source": [
        "### Model 1: Decision Tree Classifier\n",
        "\n",
        "Our first model will be using scikit-learn Pipelines. \n",
        "\n",
        "Inside our pipeline, we'll firstly vectorize the input data by converting the quote to their TFIDF formation. This will convert our string Quotes to becoming numerical values for input. Then, we have to consider how we will be handling multiple classes. We'll try with a OneVsRest classifier, because this will allow us to pass in each tag and use an single-class estimator on each tag's train and test data. \n",
        "\n",
        "However, we need to wrap the OneVsRest classifier around an estimator that makes sense for what we are trying to achieve here. We'll use a Decision tree classifier, because the sklearn functionality is pretty simplistic, doesnt require much shaping of the data, and should hopefully set a good basis for our first try. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6d3b9cf",
      "metadata": {
        "id": "f6d3b9cf"
      },
      "outputs": [],
      "source": [
        "dt_classifier = Pipeline([('tfidf', TfidfVectorizer()), ('clf', OneVsRestClassifier(DecisionTreeClassifier()))])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcfc7702",
      "metadata": {
        "id": "dcfc7702"
      },
      "source": [
        "Now, we'll loop through each of the tags in our dataset, train our model on that particular tag, and then append it to a dictionary containg each tag and that tag's associated evaluation score. \n",
        "\n",
        "For our evaluating metric, we'll choose to use f1 scores over accuracy, because if we look at our data, we have an imbalance of tags. Some quotes have several tags, while others only have one or two. As such, using accuracy would likely not work well for this scenario. \n",
        "\n",
        "However, we have multiple classes, so it would not make much sense to get a bunch of f1 scores since each tag would give different results. We can instead collect each tag's precision and recall from when the model's predictions are compared to the actual test data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29223acb",
      "metadata": {
        "id": "29223acb"
      },
      "outputs": [],
      "source": [
        "prec_recs = {}\n",
        "for tag in gr_tags:\n",
        "    \n",
        "    dt_classifier.fit(x_tr, train[tag])\n",
        "    prediction = dt_classifier.predict(x_te)\n",
        "    \n",
        "    precision_recall = precision_recall_fscore_support(test[tag], prediction, average = 'macro')\n",
        "    prec_recs[tag] = precision_recall"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42c71ad3",
      "metadata": {
        "id": "42c71ad3"
      },
      "source": [
        "So now we can calculate the average precision and recall for our tags by looping through our dictionary, summing up the total of both metrics, and dividing by the number of tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5590eb64",
      "metadata": {
        "id": "5590eb64"
      },
      "outputs": [],
      "source": [
        "sum_precision = 0\n",
        "sum_recall = 0\n",
        "\n",
        "for key in prec_recs.keys():\n",
        "    \n",
        "    sum_precision += prec_recs[key][0]\n",
        "    sum_recall += prec_recs[key][1]\n",
        "    \n",
        "mean_precision = sum_precision / len(prec_recs.keys())\n",
        "mean_recall = sum_recall / len(prec_recs.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8f60216",
      "metadata": {
        "id": "d8f60216"
      },
      "source": [
        "Now we apply the formula of finding an f1 score which is (2 * p * r) / (p + r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d942fa49",
      "metadata": {
        "id": "d942fa49",
        "outputId": "303ac15d-87ea-4a57-a446-df0f912efacf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7169826541146564"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "average_f1 = (2 * mean_precision * mean_recall) / (mean_precision + mean_recall)\n",
        "average_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6039cf1",
      "metadata": {
        "id": "c6039cf1"
      },
      "source": [
        "So we have an f1 score of about 0.708. F1 scores range from 0 to 1, and the closer they are to 1, the better the model, so we have set up a good baseline for ourselves. But we want to improve on this and make our model better classify our quotes. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93fd599",
      "metadata": {
        "id": "b93fd599"
      },
      "source": [
        "#### Optimizing Model 1  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68c5ea4e",
      "metadata": {
        "id": "68c5ea4e"
      },
      "source": [
        "Now that we have our baseline model, how can we optimize it? \n",
        "\n",
        "There are many concepts we can implement into our Pipeline, both from a text classification standpoint, as well as a sklearn standpoint. \n",
        "\n",
        "The first method we'll implement is getting rid of stop-words. These are words that appear extremely frequently in human language, and give very little value to our model. Removing them can allow our model to focus more strongly on the more important data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41bbe4f3",
      "metadata": {
        "id": "41bbe4f3"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "919b4ad4",
      "metadata": {
        "id": "919b4ad4"
      },
      "source": [
        "Now that we have defined the words to remove, we can try and optimize our other parameters with GridSearchCV. First, we'll need to select what parameters we can optimize. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07867f2b",
      "metadata": {
        "id": "07867f2b"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'clf':(DecisionTreeClassifier(),),\n",
        "    'clf__max_depth': [2, 3, 4, 5, 7, 10, 13, 15, 18, None],\n",
        "    'clf__min_samples_split': [2, 3, 5, 7, 10, 15, 20],\n",
        "    'clf__min_samples_leaf': [2, 3, 5, 7, 10, 15, 20]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7342d553",
      "metadata": {
        "id": "7342d553"
      },
      "source": [
        "Now we have created the parameters, we can place that into a GridSearchCV and train it on our data. \n",
        "Let's print out the best parameters we get. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b22152f",
      "metadata": {
        "id": "5b22152f",
        "outputId": "11cd87ee-4201-497a-d0ce-1169a79c4449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-affc76dac527>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgr_tags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgrids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgrids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[1;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             )\n\u001b[1;32m    357\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2075\u001b[0m         \"\"\"\n\u001b[1;32m   2076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfeature_idx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_counter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m                         \u001b[0mfeature_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "grids = GridSearchCV(dt_classifier, param_grid = parameters, cv = 3, return_train_score = True)\n",
        "for tag in gr_tags:\n",
        "    grids.fit(x_tr, train[tag])\n",
        "\n",
        "grids.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e25b700",
      "metadata": {
        "id": "9e25b700"
      },
      "source": [
        "Let's now re-run our training, testing, and calculating of precision and recall to calculate a new and hopefully improved average f1 score. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeb2a078",
      "metadata": {
        "id": "eeb2a078",
        "outputId": "e0613ef9-74c8-42ee-d0bb-21116dc94deb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.781000574625376"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "dt_classifier = Pipeline([('tdidf', TfidfVectorizer(stop_words = stop_words)), ('dtc', DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 2))])\n",
        "\n",
        "prec_recs = {}\n",
        "for tag in gr_tags:\n",
        "    \n",
        "    dt_classifier.fit(x_tr, train[tag])\n",
        "    prediction = dt_classifier.predict(x_te)\n",
        "    \n",
        "    precision_recall = precision_recall_fscore_support(test[tag], prediction, average = 'macro')\n",
        "    prec_recs[tag] = precision_recall\n",
        "\n",
        "sum_precision = 0\n",
        "sum_recall = 0\n",
        "\n",
        "for key in prec_recs.keys():\n",
        "    \n",
        "    sum_precision += prec_recs[key][0]\n",
        "    sum_recall += prec_recs[key][1]\n",
        "    \n",
        "mean_precision = sum_precision / len(prec_recs.keys())\n",
        "mean_recall = sum_recall / len(prec_recs.keys())\n",
        "\n",
        "average_f1 = (2 * mean_precision * mean_recall) / (mean_precision + mean_recall)\n",
        "average_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e679a6a3",
      "metadata": {
        "id": "e679a6a3"
      },
      "source": [
        "So we see a decent improvement from 0.7 --> 0.77, achieved with GridSearchCV and stop_word inclusion to optimize our model. However, we'll take a look at other models / optimizations to see if we can get a heightened score. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84a537a2",
      "metadata": {
        "id": "84a537a2"
      },
      "source": [
        "### Model 2: "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "goodreads = goodreads[goodreads['isEmpty'] == False]\n",
        "goodreads['stop_quote'] = goodreads['quote'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "goodreads['stop_tags'] = goodreads['tags'].apply(lambda x: [z for z in x if z not in stop_words])\n",
        "\n",
        "goodreads.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "lVdL9EQQZ8cO",
        "outputId": "f520c932-a2ec-4f87-c6ea-e5f36ab744f6"
      },
      "id": "lVdL9EQQZ8cO",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-28f268ad-b08c-4844-8977-65650da4f614\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "      <th>tags</th>\n",
              "      <th>isEmpty</th>\n",
              "      <th>stop_quote</th>\n",
              "      <th>stop_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>be yourself everyone else is already taken</td>\n",
              "      <td>[attributed, no, source, be, yourself, gilbert...</td>\n",
              "      <td>False</td>\n",
              "      <td>everyone else already taken</td>\n",
              "      <td>[attributed, source, gilbert, perreira, honest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im selfish impatient and a little insecure i m...</td>\n",
              "      <td>[attributed, no, source, best, life, love, mis...</td>\n",
              "      <td>False</td>\n",
              "      <td>im selfish impatient little insecure make mist...</td>\n",
              "      <td>[attributed, source, best, life, love, mistake...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>two things are infinite the universe and human...</td>\n",
              "      <td>[attributed, no, source, human, nature, humor,...</td>\n",
              "      <td>False</td>\n",
              "      <td>two things infinite universe human stupidity i...</td>\n",
              "      <td>[attributed, source, human, nature, humor, inf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>so many books so little time</td>\n",
              "      <td>[books, humor]</td>\n",
              "      <td>False</td>\n",
              "      <td>many books little time</td>\n",
              "      <td>[books, humor]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a room without books is like a body without a ...</td>\n",
              "      <td>[attributed, no, source, books, simile, soul]</td>\n",
              "      <td>False</td>\n",
              "      <td>room without books like body without soul</td>\n",
              "      <td>[attributed, source, books, simile, soul]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28f268ad-b08c-4844-8977-65650da4f614')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28f268ad-b08c-4844-8977-65650da4f614 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28f268ad-b08c-4844-8977-65650da4f614');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               quote  \\\n",
              "0         be yourself everyone else is already taken   \n",
              "1  im selfish impatient and a little insecure i m...   \n",
              "2  two things are infinite the universe and human...   \n",
              "3                       so many books so little time   \n",
              "4  a room without books is like a body without a ...   \n",
              "\n",
              "                                                tags  isEmpty  \\\n",
              "0  [attributed, no, source, be, yourself, gilbert...    False   \n",
              "1  [attributed, no, source, best, life, love, mis...    False   \n",
              "2  [attributed, no, source, human, nature, humor,...    False   \n",
              "3                                     [books, humor]    False   \n",
              "4      [attributed, no, source, books, simile, soul]    False   \n",
              "\n",
              "                                          stop_quote  \\\n",
              "0                        everyone else already taken   \n",
              "1  im selfish impatient little insecure make mist...   \n",
              "2  two things infinite universe human stupidity i...   \n",
              "3                             many books little time   \n",
              "4          room without books like body without soul   \n",
              "\n",
              "                                           stop_tags  \n",
              "0  [attributed, source, gilbert, perreira, honest...  \n",
              "1  [attributed, source, best, life, love, mistake...  \n",
              "2  [attributed, source, human, nature, humor, inf...  \n",
              "3                                     [books, humor]  \n",
              "4          [attributed, source, books, simile, soul]  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "goodreads_sample = goodreads.sample(frac = 1)\n",
        "goodreads_sample = goodreads_sample[['stop_tags', 'stop_quote']]\n",
        "train, test = train_test_split(goodreads_sample, test_size = 0.2, shuffle = True)\n",
        "val = test.sample(frac=0.5)\n",
        "test.drop(val.index, inplace=True)\n",
        "train.shape, test.shape, val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USBExS3qxJmd",
        "outputId": "4d1feeeb-1bcb-4d8c-d562-f2cf97b401b8"
      },
      "id": "USBExS3qxJmd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2003, 2), (251, 2), (250, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "from tensorflow.ragged import constant\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "terms = constant(train[\"stop_tags\"].values)\n",
        "lookup = layers.StringLookup(output_mode=\"multi_hot\")\n",
        "lookup.adapt(terms)\n",
        "vocab = lookup.get_vocabulary()\n",
        "\n",
        "\n",
        "def invert_multi_hot(encoded_labels):\n",
        "    \"\"\"Reverse a single multi-hot encoded label to a tuple of vocab terms.\"\"\"\n",
        "    hot_indices = np.argwhere(encoded_labels == 1.0)[..., 0]\n",
        "    return np.take(vocab, hot_indices)\n",
        "\n",
        "\n",
        "print(\"Vocabulary:\\n\")\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejX6_BOAy4AL",
        "outputId": "7582b6db-c04b-46d1-ed3f-7e67c18877d8"
      },
      "id": "ejX6_BOAy4AL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:\n",
            "\n",
            "['[UNK]', 'life', 'inspirational', 'love', 'humor', 'positive', 'books', 'quotes', 'living', 'self', 'reading', 'misattributed', 'inspiration', 'writing', 'philosophy', 'happiness', 'friendship', 'wisdom', 'truth', 'attributed', 'source', 'jace', 'thinking', 'death', 'optimism', 'romance', 'hope', 'women', 'poetry', 'lessons', 'courage', 'affirmation', 'optimistic', 'inspiring', 'inspire', 'attitude', 'relationships', 'pain', 'change', 'wayland', 'religion', 'music', 'clary', 'god', 'funny', 'fear', 'dreams', 'strength', 'science', 'friends', 'freedom', 'time', 'motivational', 'loneliness', 'fray', 'city', 'words', 'success', 'sadness', 'motivation', 'beauty', 'heart', 'reality', 'faith', 'determination', 'men', 'individuality', 'education', 'stars', 'literature', 'kindness', 'humanity', 'grief', 'go', 'future', 'empowerment', 'art', 'herondale', 'family', 'dumbledore', 'world', 'power', 'potter', 'people', 'peace', 'nature', 'mortal', 'loss', 'letting', 'knowledge', 'instruments', 'humour', 'human', 'harry', 'fantasy', 'depression', 'confidence', 'trust', 'suffering', 'mind', 'marriage', 'light', 'learning', 'john', 'intelligence', 'failure', 'belief', 'war', 'true', 'stories', 'soul', 'live', 'independence', 'hunger', 'experience', 'children', 'bravery', 'sarcasm', 'politics', 'past', 'mistakes', 'imagination', 'identity', 'honesty', 'games', 'feminism', 'compassion', 'wonder', 'understanding', 'travel', 'sparks', 'simon', 'sex', 'respect', 'percy', 'nicholas', 'moving', 'memory', 'man', 'magic', 'lightwood', 'lies', 'laughter', 'jackson', 'inner', 'growth', 'green', 'good', 'glass', 'food', 'fiction', 'advice', 'adventure', 'work', 'weasley', 'smile', 'sense', 'sad', 'sacrifice', 'open', 'katniss', 'hurt', 'heartbreak', 'hate', 'growing', 'gratitude', 'goodness', 'forgiveness', 'fault', 'evil', 'einstein', 'clockwork', 'character', 'bones', 'believe', 'atheism', 'animals', 'anger', 'acceptance', 'suicide', 'spiritual', 'solitude', 'silence', 'roosevelt', 'reason', 'purpose', 'peeta', 'paraphrased', 'others', 'morality', 'lewis', 'integrity', 'ignorance', 'healing', 'fate', 'eleanor', 'dream', 'disappointment', 'diem', 'day', 'crying', 'classic', 'carpe', 'book', 'age', 'worry', 'wise', 'way', 'twain', 'tears', 'tales', 'stupidity', 'spirituality', 'sleep', 'seuss', 'scars', 'quote', 'prince', 'perseverance', 'perception', 'night', 'new', 'memories', 'meaning', 'mark', 'mankind', 'magnus', 'loved', 'joy', 'history', 'gender', 'flying', 'fairy', 'empathy', 'discovery', 'clare', 'choices', 'cats', 'beatles', 'bane', 'awareness', 'alice', 'activism', 'action', 'writers', 'wonderland', 'wit', 'wallflower', 'vampire', 'thought', 'tfios', 'society', 'simile', 'secrets', 'risk', 'right', 'responsibility', 'present', 'poem', 'perspective', 'patience', 'passion', 'mother', 'mindedness', 'lost', 'libraries', 'last', 'kiss', 'isabelle', 'irony', 'insanity', 'hell', 'gray', 'giving', 'girls', 'first', 'fighting', 'feelings', 'fallen', 'emotions', 'elizabeth', 'edward', 'dreaming', 'desire', 'darkness', 'comfort', 'comedy', 'cassandra', 'authentic', 'angels', 'angel', 'alaska', 'adversity', 'young', 'widely', 'voice', 'universe', 'thoughts', 'tessa', 'teresa', 'souls', 'song', 'social', 'school', 'ron', 'romantic', 'rights', 'read', 'persistence', 'perfection', 'parents', 'mythology', 'mothers', 'monroe', 'money', 'marilyn', 'madness', 'lying', 'looking', 'longing', 'library', 'language', 'justice', 'james', 'infatuation', 'improvement', 'holden', 'hobbes', 'hatred', 'happy', 'greatness', 'goodbye', 'goals', 'george', 'forgetting', 'fire', 'fearless', 'expectations', 'ethics', 'esteem', 'enjoy', 'enemies', 'encouragement', 'dying', 'dr', 'dogs', 'divergent', 'destiny', 'cry', 'creativity', 'common', 'christianity', 'choice', 'chocolate', 'childhood', 'carstairs', 'calvin', 'brave', 'benediction', 'bella', 'ashes', 'alec', 'youth', 'yearning', 'writer', 'wishes', 'william', 'wealth', 'water', 'virtue', 'value', 'unrequited', 'unhappiness', 'trial', 'think', 'temptation', 'teen', 'sweet', 'survival', 'strategy', 'storytelling', 'stop', 'stereotypes', 'start', 'sorrow', 'snape', 'sin', 'sight', 'sharing', 'reliance', 'regret', 'quip', 'qotd', 'psychology', 'problems', 'prayer', 'perks', 'parenting', 'olympians', 'obsession', 'notebook', 'never', 'name', 'morals', 'moment', 'mockingjay', 'mellark', 'malfoy', 'lovers', 'little', 'lincoln', 'liberty', 'learn', 'knowing', 'journey', 'joke', 'jem', 'insult', 'innocence', 'image', 'hypocrisy', 'humorous', 'helping', 'heaven', 'heartache', 'give', 'forward', 'flight', 'finnick', 'fashion', 'expression', 'equality', 'emotion', 'eat', 'dragons', 'dignity', 'deep', 'deception', 'dating', 'dance', 'creative', 'creation', 'control', 'contentment', 'conformity', 'chase', 'chapter', 'chances', 'challenges', 'catching', 'carroll', 'bennet', 'bad', 'authors', 'ataraxy', 'appreciation', 'annabeth', 'albert', 'achievement', 'zone', 'zen', 'year', 'wounds', 'worth', 'worrying', 'woman', 'wish', 'wings', 'winds', 'wind', 'wilde', 'wife', 'waters', 'wander', 'victory', 'values', 'valentine', 'uplifting', 'unknown', 'unity', 'unbreakable', 'twilight', 'trying', 'trouble', 'tris', 'trials', 'trees', 'tobias', 'ties', 'things', 'thief', 'thankful', 'teachers', 'tea', 'taste', 'talent', 'taking', 'storms', 'stone', 'steinem', 'standards', 'spirit', 'speech', 'speaking', 'sonnet', 'smiling', 'smiles', 'smart', 'six', 'sing', 'silent', 'shakespeare', 'service', 'sentence', 'selfishness', 'security', 'secret', 'seasons', 'scout', 'scotland', 'sardothien', 'sanity', 'saint', 'run', 'ruby', 'rothfuss', 'roses', 'rose', 'romeo', 'road', 'rich', 'rhysand', 'revenge', 'remaining', 'relationship', 'reincarnation', 'realization', 'real', 'readers', 'reader', 'rationality', 'questions', 'protection', 'propaganda', 'progress', 'process', 'pretty', 'pretend', 'poverty', 'potential', 'possibilities', 'pooh', 'pleasure', 'places', 'physics', 'personal', 'patrick', 'patch', 'parting', 'paraphrase', 'paradox', 'paradise', 'oscar', 'organized', 'opportunity', 'opinions', 'opening', 'old', 'nora', 'nonsense', 'nin', 'nerdfighters', 'myth', 'mortality', 'morgenstern', 'moon', 'molly', 'mist', 'missed', 'miracles', 'minds', 'mindfulness', 'milne', 'meyer', 'metaphysics', 'mercy', 'meaningful', 'maturity', 'manners', 'make', 'mad', 'luck', 'logic', 'listening', 'lines', 'limits', 'letters', 'letter', 'let', 'lennon', 'lecture', 'leadership', 'leaders', 'leader', 'laugh', 'kind', 'kill', 'keep', 'juliet', 'judgment', 'judgement', 'jordan', 'jesus', 'jealousy', 'jane', 'introspection', 'infinity', 'infidelity', 'importance', 'hush', 'husband', 'humility', 'humbert', 'humans', 'house', 'hot', 'horror', 'hopelessness', 'hidden', 'hg2g', 'heroes', 'hepburn', 'heathcliff', 'health', 'hazel', 'haunting', 'haiku', 'grey', 'grace', 'gossip', 'gold', 'gloria', 'gilbert', 'gift', 'gandhi', 'g', 'fury', 'friend', 'free', 'fred', 'four', 'foolishness', 'fight', 'feyre', 'ferret', 'farm', 'fame', 'falling', 'facts', 'fact', 'eyes', 'existence', 'endings', 'ego', 'ecstasy', 'earth', 'e', 'dursley', 'drugs', 'drinking', 'drama', 'double', 'distance', 'direction', 'dimitri', 'different', 'diary', 'destruction', 'despair', 'desires', 'depressing', 'demons', 'democracy', 'decisions', 'deadlines', 'dark', 'dare', 'daily', 'curiosity', 'crows', 'crime', 'crazy', 'court', 'couples', 'conscience', 'companionship', 'commentary', 'collins', 'classics', 'class', 'christmas', 'christina', 'chivalry', 'chinese', 'charming', 'charity', 'challenge', 'censorship', 'celaena', 'catherine', 'carlin', 'caring', 'care', 'call', 'brown', 'broken', 'boys', 'body', 'blessed', 'bill', 'bible', 'betrayal', 'beautiful', 'beatrice', 'beatitudes', 'awesome', 'awe', 'autumn', 'authenticity', 'austen', 'augustus', 'attraction', 'athena', 'assurance', 'arts', 'appreciate', 'apple', 'apollo', 'apathy', 'answers', 'anne', 'animal', 'anais', 'america', 'ambiguity', 'alone', 'aliteracy', 'albus', 'affection', 'adult', 'addiction', 'adaptation', 'acomaf', 'academy', 'abraham', 'abilities', 'abe', 'حب', 'zsadist', 'zombies', 'zoe', 'zeus', 'youthfulness', 'yesterday', 'ya', 'xxiii', 'xvii', 'x', 'write', 'wring', 'worst', 'worship', 'wormtail', 'wizard', 'witty', 'wither', 'witch', 'wisher', 'wisedom', 'winter', 'winnie', 'wine', 'windows', 'willful', 'wilhelm', 'wilderness', 'wicked', 'whole', 'white', 'whiskey', 'westfall', 'werewolf', 'well', 'weirdness', 'weight', 'weakness', 'wayne', 'watch', 'warriors', 'warrior', 'want', 'wanda', 'waking', 'waiting', 'vow', 'voting', 'voter', 'vorkosigan', 'volunteerism', 'vlog', 'visions', 'vision', 'violence', 'viereck', 'veronica', 'vegetarianism', 'van', 'vacation', 'us', 'ups', 'unsourced', 'unseen', 'unpredictability', 'unlikely', 'unhappy', 'unfairness', 'understand', 'uncle', 'uncertainty', 'unburdening', 'ugly', 'tyler', 'twirl', 'try', 'truths', 'truthful', 'troubles', 'troublemakers', 'triumph', 'treasure', 'trauma', 'trap', 'transform', 'transcendentalism', 'tragedy', 'towns', 'towel', 'touchstones', 'top', 'tomorrow', 'tom', 'tolstoy', 'toilet', 'together', 'tmi', 'tired', 'tintern', 'tina', 'timelessness', 'ticking', 'thumb', 'throne', 'thoughtful', 'thorns', 'thirst', 'thing', 'thievery', 'theology', 'thanksgiving', 'thankfulness', 'thank', 'thalia', 'telling', 'tell', 'television', 'teens', 'teenagers', 'teenager', 'teenage', 'tedious', 'teasing', 'teaching', 'teach', 'taylor', 'tanner', 'talking', 'talk', 'talents', 'sympathy', 'swift', 'sweetness', 'swear', 'swan', 'suzanne', 'suspicion', 'superiority', 'sunset', 'sun', 'summer', 'sullivan', 'sufi', 'sufficiency', 'suess', 'submission', 'stubbornness', 'struggle', 'strong', 'strigoi', 'stressed', 'stress', 'strenth', 'story', 'stoicism', 'steve', 'steppenwolf', 'stephenie', 'stephen', 'step', 'stekel', 'status', 'statistics', 'stand', 'stake', 'spring', 'spinsterhood', 'speed', 'space', 'soulmates', 'sorry', 'sorcerers', 'sophie', 'soon', 'songs', 'socks', 'snow', 'slaughterhouse', 'slammed', 'skills', 'skepticism', 'skeptic', 'sisters', 'sirius', 'sins', 'sinner', 'sinister', 'singles', 'single', 'singer', 'simplicity', 'simon_bolivar', 'silverman', 'silly', 'silliness', 'shrugged', 'show', 'shock', 'ship', 'shine', 'sherlock', 'shelves', 'shelter', 'shedd', 'share', 'shampoo', 'shame', 'shadowhunters', 'shades', 'sexuality', 'serenity', 'seperate', 'separation', 'sentimentality', 'semicolons', 'semantics', 'selection', 'seize', 'seeing', 'seeds', 'seduction', 'sebastian', 'searching', 'scott', 'scifi', 'sci', 'scholars', 'scar', 'save', 'sausage', 'satisfaction', 'satirical', 'sarah', 'santiago', 'santayana', 'sandman', 'samuel', 'salinger', 'sal', 'sail', 'saga', 'safety', 'safe', 's_labyrinth', 'rythmic', 'runner', 'rumi', 'rulers', 'rue', 'rowling', 'roth', 'rosemarie', 'rosa', 'roots', 'romantics', 'roles', 'role', 'rocks', 'robin', 'robert', 'richness', 'richelle', 'rice', 'rewriting', 'rewind', 'revolution', 'revelation', 'reticence', 'restlessness', 'resilience', 'rescuing', 'requirements', 'reputation', 'renaissance', 'rena', 'remus', 'reminding', 'remembrance', 'remember', 'religious', 'relaxation', 'regrets', 'reggae', 'refuge', 'reflection', 'reflect', 'redemption', 'records', 'recognition', 'reciprocity', 'receptivity', 'rebirth', 'rebels', 'rebellion', 'reassurance', 'really', 'realist', 'realism', 'reads', 'reach', 'rationalism', 'ralph', 'rachel', 'rabelais', 'quotation', 'quo', 'quiet', 'questioning', 'question', 'quest', 'purity', 'puppies', 'punishment', 'puck', 'public', 'psychotherapist', 'psychological', 'provoking', 'proverb', 'protest', 'prose', 'promise', 'progressive', 'profound', 'profanity', 'procrastination', 'procrastinate', 'proactivity', 'privilege', 'privacy', 'principle', 'pride', 'pressure', 'presidential', 'pray', 'pox', 'possiblity', 'possibility', 'positivity', 'posiedon', 'poseidon', 'popularity', 'ponyboy', 'ponder', 'pleasures', 'plays', 'play', 'plants', 'plans', 'planning', 'plague', 'pixie', 'pijamas', 'pigs', 'piglet', 'pig', 'philosphy', 'philosophical', 'philosophers', 'phenomenal', 'pets', 'peter', 'pessimism', 'perreira', 'permission', 'perfect', 'peer', 'peabody', 'pause', 'paulo', 'pattern', 'passage', 'parties', 'parks', 'park', 'paraphrasing', 'paranormal', 'paramore', 'paper', 'paolini', 'panic', 'pandora', 'pan', 'pamuk', 'owen', 'originality', 'orhan', 'ordinary', 'options', 'oprah', 'opposition', 'opposite', 'opinion', 'openness', 'ones', 'one', 'odair', 'october', 'ocean', 'obviousness', 'obvious', 'observational', 'obedience', 'oaths', 'novelty', 'novelist', 'novel', 'nothing', 'north', 'norms', 'nonfiction', 'nonconformity', 'nightshade', 'nightmares', 'nietzsche', 'news', 'neverland', 'neurosis', 'nerds', 'nerd', 'nephlim', 'neighborhoods', 'needs', 'need', 'nations', 'nationalism', 'nagasawa', 'mythological', 'mystery', 'mutuality', 'mustache', 'musical', 'murder', 'mummies', 'muggles', 'much', 'mr', 'move', 'mountains', 'mottos', 'mortification', 'morning', 'mormont', 'morganvillevampires', 'moonshine', 'monsters', 'moi', 'models', 'mistake', 'missing', 'misquote', 'misprints', 'misogyny', 'misfits', 'misery', 'mischief', 'misanthropy', 'mirror', 'miracle', 'minutes', 'minority', 'mindful', 'mina', 'miller', 'miles', 'middlemarch', 'metaphor', 'mentoring', 'memoir', 'melanie', 'melancholy', 'mead', 'mazur', 'may', 'max', 'matthias', 'matthews', 'matters', 'matter', 'matrimony', 'marx', 'martyr', 'marley', 'many', 'malediction', 'malcolm', 'makeup', 'majority', 'mail', 'maia', 'magnificent', 'machines', 'macchio', 'macbeth', 'lupin', 'lullaby', 'luke', 'loyalty', 'lover', 'louisa', 'lookingforalaska', 'longings', 'loner', 'lonely', 'london', 'logo', 'loathing', 'literacy', 'limitations', 'limit', 'lightning', 'liar', 'lesson', 'less', 'lena', 'lemons', 'leigh', 'legacy', 'laziness', 'layken', 'law', 'lateral', 'late', 'lamp', 'l', 'kyle', 'kvothe', 'kurt', 'kite', 'kissing', 'kingdom', 'kindle', 'killing', 'kensington', 'katherines', 'katharine', 'kant', 'kafka', 'k', 'june', 'judging', 'judge', 'joseph', 'johnny', 'johngreen', 'joh', 'jobs', 'jk', 'jest', 'jeb', 'jared', 'jamie', 'jail', 'jacob', 'ivashkov', 'italy', 'isolation', 'isaac', 'invincible', 'investigator', 'invention', 'intoxication', 'intimidation', 'interview', 'intent', 'intelligent', 'intellectuals', 'intellect', 'insults', 'insincerity', 'inkheart', 'injustice', 'injury', 'injuries', 'initiative', 'ingenuity', 'infinite', 'inevitability', 'inertia', 'inequality', 'inej', 'indulgence', 'individuals', 'individualism', 'indifference', 'independent', 'incrementalism', 'incredibly', 'inconvenient', 'imposters', 'impossible', 'imperfections', 'imperfection', 'impact', 'immature', 'imagery', 'illusions', 'illiteracy', 'ignite', 'idiocy', 'ideas', 'ideals', 'ian', 'hutchins', 'humanities', 'humanism', 'host', 'hopper', 'honor', 'holoway', 'holmes', 'hodge', 'hmmm', 'hitchhiker', 'historical', 'hindsight', 'high', 'hermione', 'henry', 'helsing', 'help', 'heartfelt', 'heartbreaking', 'heal', 'haunt', 'hatter', 'hathaway', 'hamlet', 'halter', 'hagrid', 'h2g2', 'guys', 'gullibility', 'guide', 'grudges', 'grudge', 'grown', 'ground', 'groucho', 'grisha', 'grieving', 'greg', 'greek', 'great', 'grammar', 'governments', 'government', 'goodwill', 'goodfellow', 'goodbyes', 'gonzo', 'gondor', 'going', 'gods', 'glittering', 'glitter', 'girl', 'ginny', 'ghosts', 'ghafa', 'geography', 'genius', 'generations', 'gates', 'gardens', 'gandalf', 'game', 'gaiman', 'funeral', 'fun', 'fuck', 'frost', 'frolick', 'frodo', 'frienship', 'fresh', 'french', 'freethinker', 'fraser', 'franz', 'franklin', 'francois', 'fountainhead', 'foster', 'forgive', 'forgetfulness', 'forever', 'forests', 'foreshadowing', 'forcasting', 'foolproof', 'fool', 'focus', 'flowers', 'flexibility', 'flewn', 'flaws', 'flattery', 'flame', 'five', 'fitzpatrick', 'fitzgerald', 'fitting', 'finding', 'finch', 'finale', 'fig', 'fifty', 'fi', 'fey', 'ferocity', 'feminist', 'femininity', 'feet', 'feeling', 'feathers', 'fears', 'fearlessness', 'favourite', 'families', 'fall', 'fairytales', 'fairies', 'fair', 'failures', 'fahrenheit', 'f', 'exupery', 'extraterrestrials', 'explore', 'exploration', 'explain', 'expectation', 'exercise', 'excuses', 'excuse', 'evidence', 'everything', 'everyday', 'everdeen', 'essential', 'essay', 'escape', 'eragon', 'equations', 'entry', 'enthusiasm', 'enterprise', 'england', 'energy', 'enemy', 'enduring', 'emptiness', 'emerson', 'elizabethan', 'elitist', 'elitism', 'elite', 'eleven', 'elections', 'edison', 'ecology', 'eccentricity', 'ebay', 'eating', 'eastern', 'earnestness', 'dystopia', 'dust', 'durden', 'drunk', 'dreamers', 'dreamer', 'dramatist', 'dracula', 'draco', 'douglas', 'doubt', 'dorian', 'doctor', 'dna', 'dizziness', 'divorce', 'dives', 'diversity', 'distractions', 'dissent', 'dissapointment', 'dislike', 'dishonesty', 'disease', 'discworld', 'discussion', 'discipline', 'disappointed', 'dirty', 'dirt', 'diplomacy', 'dionysus', 'difficulty', 'difficult', 'difference', 'die', 'dictionary', 'dhampir', 'devotion', 'devil', 'detection', 'dessen', 'design', 'description', 'deprecation', 'denial', 'demon', 'demographics', 'delusion', 'defiant', 'defenses', 'defend', 'deeply', 'december', 'deceit', 'dear', 'dead', 'de', 'dave', 'dauntless', 'darcy', 'dangerous', 'danger', 'dancing', 'dan', 'cynicism', 'cynical', 'cynic', 'curtis', 'cruelty', 'crooked', 'criticize', 'crisis', 'craziness', 'cows', 'courtroom', 'cosmos', 'cosby', 'corruption', 'correct', 'conviction', 'conversations', 'contrast', 'consolation', 'consciousness', 'connecting', 'congreve', 'confused', 'conflict', 'confidences', 'confession', 'condition', 'concern', 'computers', 'completion', 'complaining', 'company', 'communication', 'commercial', 'commerce', 'coma', 'color', 'college', 'coldness', 'coelho', 'cobain', 'clouds', 'clothing', 'clothes', 'close', 'clock', 'clichés', 'cleverness', 'cleanliness', 'clean', 'clark', 'claire', 'civil', 'cinna', 'church', 'christopher', 'christians', 'christian', 'christ', 'choose', 'chesterton', 'chemistry', 'cheese', 'check', 'chbosky', 'charlie', 'characters', 'chaos', 'chaol', 'changes', 'chance', 'chalmers', 'challanges', 'caulfield', 'catatonia', 'castle', 'cartoonist', 'carolina', 'capability', 'canoodle', 'cancer', 'canadian', 'camus', 'calling', 'cade', 'c', 'button', 'busy', 'burdens', 'buddhism', 'brotherhood', 'brokenness', 'broccoli', 'broad', 'british', 'bright', 'bridge', 'breath', 'breakup', 'breakfast', 'brain', 'box', 'bower', 'bothered', 'bossypants', 'boredom', 'bookroom', 'bond', 'boggs', 'bodett', 'bob', 'blues', 'blood', 'blog', 'blackjack', 'black', 'biscuit', 'birthday', 'birth', 'birds', 'bilbo', 'bibliophiles', 'betty', 'bestseller', 'best', 'bereavement', 'benjamin', 'ben', 'belonging', 'believing', 'beliefs', 'behrendt', 'behind', 'beginnings', 'beckett', 'becca', 'bathing', 'barriers', 'barrie', 'bardugo', 'barbarity', 'baker', 'bachelorhood', 'baby', 'babies', 'awkward', 'awesomeness', 'autonomy', 'audrey', 'atticus', 'attention', 'atrocities', 'atoms', 'atlas', 'atheist', 'athe', 'astronomer', 'assumptions', 'assessment', 'assassin', 'aspirations', 'aspiration', 'asimov', 'arrogance', 'armstrong', 'aristotle', 'ardor', 'april', 'appeal', 'apothegm', 'apocryphal', 'apocalypse', 'apart', 'anxiety', 'antolini', 'antoine', 'antipathy', 'anti', 'annie', 'anarchy', 'amsterdam', 'amorality', 'amnesia', 'amity', 'americans', 'amelia', 'ambition', 'amazing', 'aloneness', 'allergies', 'allegory', 'alcott', 'alcohol', 'alchohol', 'agree', 'agnosticism', 'agency', 'agama', 'afternoon', 'afraid', 'aesthetics', 'advocacy', 'advertising', 'adventuring', 'adventures', 'adults', 'adrian', 'adoration', 'addison', 'adams', 'adam', 'acts', 'actions', 'act', 'acorns', 'aciman', 'ache', 'accomplishment', 'accept', 'abundance', 'absurdities', 'absence', 'abbey', '8', '451', '24', '2013', '2012', '2008', '1997', '1993', '1970', '1955', '1929']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_label = train[\"stop_tags\"].iloc[0]\n",
        "print(f\"Original label: {sample_label}\")\n",
        "\n",
        "label_binarized = lookup([sample_label])\n",
        "print(f\"Label-binarized representation: {label_binarized}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okXNZkrd5GII",
        "outputId": "e95c420c-f712-4c4b-c353-fb4801742fe8"
      },
      "id": "okXNZkrd5GII",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original label: ['nietzsche']\n",
            "Label-binarized representation: [[0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"stop_quote\"].apply(lambda x: len(x.split(\" \"))).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOxTfAAy5Uul",
        "outputId": "c74c175b-c284-4b2b-ea8f-9998b88df2d2"
      },
      "id": "nOxTfAAy5Uul",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2003.000000\n",
              "mean       14.644533\n",
              "std        21.874984\n",
              "min         1.000000\n",
              "25%         6.000000\n",
              "50%         8.000000\n",
              "75%        15.000000\n",
              "max       348.000000\n",
              "Name: stop_quote, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seqlen = 10\n",
        "batch_size = 6\n",
        "padding_token = \"<pad>\"\n",
        "\n",
        "from tensorflow.data import AUTOTUNE\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "auto = AUTOTUNE\n",
        "\n",
        "\n",
        "def make_dataset(dataframe, is_train=True):\n",
        "    labels = constant(dataframe[\"stop_tags\"].values)\n",
        "    label_binarized = lookup(labels).numpy()\n",
        "\n",
        "    dataset = Dataset.from_tensor_slices(\n",
        "        (dataframe[\"stop_quote\"].values, label_binarized)\n",
        "    )\n",
        "\n",
        "    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
        "    return dataset.batch(batch_size)\n",
        "\n",
        "train_dataset = make_dataset(train, is_train=True)\n",
        "validation_dataset = make_dataset(val, is_train=False)\n",
        "test_dataset = make_dataset(test, is_train=False)"
      ],
      "metadata": {
        "id": "6NBCdZQp6HDo"
      },
      "id": "6NBCdZQp6HDo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = set()\n",
        "train[\"stop_quote\"].str.lower().str.split().apply(vocabulary.update)\n",
        "vocabulary_size = len(vocabulary)\n",
        "print(vocabulary_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAUc4TeW6eW9",
        "outputId": "29c90def-3150-44f6-b8b6-230a088f09dd"
      },
      "id": "NAUc4TeW6eW9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer = layers.TextVectorization(max_tokens=vocabulary_size, ngrams=2, output_mode=\"tf_idf\")\n",
        "\n",
        "import tensorflow as tf\n",
        "# `TextVectorization` layer needs to be adapted as per the vocabulary from our\n",
        "# training set.\n",
        "with tf.device(\"/CPU:0\"):\n",
        "    text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
        "\n",
        "train_dataset = train_dataset.map(lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)\n",
        "validation_dataset = validation_dataset.map(lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)\n",
        "test_dataset = test_dataset.map(lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)"
      ],
      "metadata": {
        "id": "HCapfP8E60VO"
      },
      "id": "HCapfP8E60VO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_model = Sequential()\n",
        "keras_model.add(Dropout(0.2))\n",
        "keras_model.add(Dense(1000, activation = 'relu'))\n",
        "keras_model.add(Dense(500, activation = 'relu'))\n",
        "keras_model.add(Dense(lookup.vocabulary_size(), activation = 'sigmoid'))\n",
        "\n",
        "keras_model.compile(loss=\"binary_crossentropy\", optimizer = 'adam', metrics=['categorical_accuracy'])\n",
        "keras_model.build((None, vocabulary_size))\n",
        "keras_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1Zq4ywP7GB9",
        "outputId": "87a409ad-22b2-4503-851b-9644f556898b"
      },
      "id": "G1Zq4ywP7GB9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_10 (Dropout)        (None, 6914)              0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 1000)              6915000   \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 1824)              1825824   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,741,824\n",
            "Trainable params: 9,741,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = keras_model.fit(train_dataset, \n",
        "                          validation_data = validation_dataset, \n",
        "                          epochs = 15,\n",
        "                          callbacks = [EarlyStopping(monitor = 'categorical_accuracy', patience = 3)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utdWTtwS7WXG",
        "outputId": "91745ca1-cfc7-421e-8215-af127a03c499"
      },
      "id": "utdWTtwS7WXG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "334/334 [==============================] - 30s 90ms/step - loss: 8.5799e-04 - categorical_accuracy: 0.5242 - val_loss: 0.0141 - val_categorical_accuracy: 0.1160\n",
            "Epoch 2/15\n",
            "334/334 [==============================] - 25s 74ms/step - loss: 8.3807e-04 - categorical_accuracy: 0.5282 - val_loss: 0.0145 - val_categorical_accuracy: 0.1400\n",
            "Epoch 3/15\n",
            "334/334 [==============================] - 23s 68ms/step - loss: 7.8311e-04 - categorical_accuracy: 0.5232 - val_loss: 0.0142 - val_categorical_accuracy: 0.1480\n",
            "Epoch 4/15\n",
            "334/334 [==============================] - 25s 74ms/step - loss: 6.9043e-04 - categorical_accuracy: 0.5362 - val_loss: 0.0144 - val_categorical_accuracy: 0.1480\n",
            "Epoch 5/15\n",
            "334/334 [==============================] - 25s 73ms/step - loss: 5.2425e-04 - categorical_accuracy: 0.5047 - val_loss: 0.0146 - val_categorical_accuracy: 0.1600\n",
            "Epoch 6/15\n",
            "334/334 [==============================] - 23s 69ms/step - loss: 6.2435e-04 - categorical_accuracy: 0.5047 - val_loss: 0.0140 - val_categorical_accuracy: 0.1480\n",
            "Epoch 7/15\n",
            "334/334 [==============================] - 26s 77ms/step - loss: 5.7312e-04 - categorical_accuracy: 0.4908 - val_loss: 0.0162 - val_categorical_accuracy: 0.1560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = keras_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrAMk_t57Y7G",
        "outputId": "d41f6c53-4f49-4d2f-8934-c71f8407fa7b"
      },
      "id": "yrAMk_t57Y7G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 1s 14ms/step - loss: 0.0174 - categorical_accuracy: 0.1275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_result(item):\n",
        "    plt.plot(history.history[item], label=item)\n",
        "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(item)\n",
        "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_result(\"loss\")\n",
        "plot_result(\"categorical_accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "0G3y3g_U8Wvu",
        "outputId": "b782dd54-6e78-4a5d-8ff4-a67f152ba4b3"
      },
      "id": "0G3y3g_U8Wvu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset = goodreads[['stop_quote', 'stop_tags']]\n",
        "subset['rand_tag'] = subset['stop_tags'].apply(lambda x: np.random.choice(x))\n",
        "subset.head()"
      ],
      "metadata": {
        "id": "JsfZfIjeiDqc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7bfa7534-e6bf-4e3f-b6ab-c59ec87a03f9"
      },
      "id": "JsfZfIjeiDqc",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c06d8607-4788-48bf-909d-90da024047e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_quote</th>\n",
              "      <th>stop_tags</th>\n",
              "      <th>rand_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>everyone else already taken</td>\n",
              "      <td>[attributed, source, gilbert, perreira, honest...</td>\n",
              "      <td>inspirational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im selfish impatient little insecure make mist...</td>\n",
              "      <td>[attributed, source, best, life, love, mistake...</td>\n",
              "      <td>attributed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>two things infinite universe human stupidity i...</td>\n",
              "      <td>[attributed, source, human, nature, humor, inf...</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>many books little time</td>\n",
              "      <td>[books, humor]</td>\n",
              "      <td>books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>room without books like body without soul</td>\n",
              "      <td>[attributed, source, books, simile, soul]</td>\n",
              "      <td>books</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c06d8607-4788-48bf-909d-90da024047e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c06d8607-4788-48bf-909d-90da024047e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c06d8607-4788-48bf-909d-90da024047e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          stop_quote  \\\n",
              "0                        everyone else already taken   \n",
              "1  im selfish impatient little insecure make mist...   \n",
              "2  two things infinite universe human stupidity i...   \n",
              "3                             many books little time   \n",
              "4          room without books like body without soul   \n",
              "\n",
              "                                           stop_tags       rand_tag  \n",
              "0  [attributed, source, gilbert, perreira, honest...  inspirational  \n",
              "1  [attributed, source, best, life, love, mistake...     attributed  \n",
              "2  [attributed, source, human, nature, humor, inf...          human  \n",
              "3                                     [books, humor]          books  \n",
              "4          [attributed, source, books, simile, soul]          books  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = {}\n",
        "\n",
        "for tag in subset.rand_tag:\n",
        "\n",
        "  if tag not in encoded.keys():\n",
        "\n",
        "    encoded[tag] = len(encoded)\n",
        "\n",
        "subset['encoded_tag'] = subset.rand_tag.map(encoded)"
      ],
      "metadata": {
        "id": "i5NwODewwuLu"
      },
      "id": "i5NwODewwuLu",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subset = subset.sample(frac = 1).reset_index(drop = True)\n",
        "subset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ipv_1qfWxdd-",
        "outputId": "2bc363d7-26ab-4c67-f2cb-7ee7999872d7"
      },
      "id": "Ipv_1qfWxdd-",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-05db6aa1-2b72-4557-8299-25ff669826b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_quote</th>\n",
              "      <th>stop_tags</th>\n",
              "      <th>rand_tag</th>\n",
              "      <th>encoded_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>two basic motivating forces fear love afraid p...</td>\n",
              "      <td>[beatles, fear, life, love]</td>\n",
              "      <td>fear</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mountains calling must go</td>\n",
              "      <td>[nature]</td>\n",
              "      <td>nature</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>feeling completeness needed feeling empty</td>\n",
              "      <td>[emptiness, life]</td>\n",
              "      <td>emptiness</td>\n",
              "      <td>483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>man cruelest animal</td>\n",
              "      <td>[animals, cruelty, evil, man]</td>\n",
              "      <td>animals</td>\n",
              "      <td>768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id rather die way live</td>\n",
              "      <td>[independence, lena, holoway, self, determinat...</td>\n",
              "      <td>reliance</td>\n",
              "      <td>690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05db6aa1-2b72-4557-8299-25ff669826b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05db6aa1-2b72-4557-8299-25ff669826b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05db6aa1-2b72-4557-8299-25ff669826b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          stop_quote  \\\n",
              "0  two basic motivating forces fear love afraid p...   \n",
              "1                          mountains calling must go   \n",
              "2          feeling completeness needed feeling empty   \n",
              "3                                man cruelest animal   \n",
              "4                             id rather die way live   \n",
              "\n",
              "                                           stop_tags   rand_tag  encoded_tag  \n",
              "0                        [beatles, fear, life, love]       fear           59  \n",
              "1                                           [nature]     nature          187  \n",
              "2                                  [emptiness, life]  emptiness          483  \n",
              "3                      [animals, cruelty, evil, man]    animals          768  \n",
              "4  [independence, lena, holoway, self, determinat...   reliance          690  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "oCPuME83ygYC"
      },
      "id": "oCPuME83ygYC",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_encoded = to_categorical(subset.encoded_tag)\n",
        "onehot_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u48yW0cTynLu",
        "outputId": "9a517157-3092-4e3d-f4de-f4dd245db5b8"
      },
      "id": "u48yW0cTynLu",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer,TFBertModel"
      ],
      "metadata": {
        "id": "QaKmt0ScywHQ"
      },
      "id": "QaKmt0ScywHQ",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "bert = TFBertModel.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIDgRG5rzT6q",
        "outputId": "f3a5cb8d-2660-445a-9a63-4977fa007f5d"
      },
      "id": "hIDgRG5rzT6q",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = subset[['stop_quote', 'encoded_tag']]\n",
        "train, test = train_test_split(data, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "ulYA-F6xz0a8"
      },
      "id": "ulYA-F6xz0a8",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subset[\"stop_quote\"].apply(lambda x: len(x.split(\" \"))).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvftf0Xg0iSG",
        "outputId": "4b48ead0-3c66-4d43-d58c-77e4fcb8a048"
      },
      "id": "jvftf0Xg0iSG",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2504.000000\n",
              "mean       14.510783\n",
              "std        21.904413\n",
              "min         1.000000\n",
              "25%         6.000000\n",
              "50%         9.000000\n",
              "75%        15.000000\n",
              "max       348.000000\n",
              "Name: stop_quote, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = tokenizer(\n",
        "    text=train['stop_quote'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=9,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "x_test = tokenizer(\n",
        "    text=test['stop_quote'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=9,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ],
      "metadata": {
        "id": "y2QI43-m0LlZ"
      },
      "id": "y2QI43-m0LlZ",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train['encoded_tag']\n",
        "y_test = test['encoded_tag']"
      ],
      "metadata": {
        "id": "Ws5Rbsnv0nhX"
      },
      "id": "Ws5Rbsnv0nhX",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = x_train['input_ids']\n",
        "attention_mask = x_train['attention_mask']"
      ],
      "metadata": {
        "id": "ycq90snG0sy4"
      },
      "id": "ycq90snG0sy4",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Dense"
      ],
      "metadata": {
        "id": "wyHLK0vK0wER"
      },
      "id": "wyHLK0vK0wER",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 9\n",
        "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "embeddings = bert(input_ids,attention_mask = input_mask)[0] \n",
        "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "out = Dense(256, activation='relu')(out)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(64, activation = 'relu')(out)\n",
        "y = Dense(1, activation = 'sigmoid')(out)\n",
        "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
        "model.layers[2].trainable = True"
      ],
      "metadata": {
        "id": "pC4f2C0909QP"
      },
      "id": "pC4f2C0909QP",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHo5G6OV6OXb",
        "outputId": "51e9b28f-2c9b-4b6f-98e7-7804517c6e06"
      },
      "id": "tHo5G6OV6OXb",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 9)]          0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 9)]          0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 9, 7                                               \n",
            "                                68),                                                              \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 768)         0           ['tf_bert_model[2][0]']          \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 256)          196864      ['global_max_pooling1d_2[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_39 (Dropout)           (None, 256)          0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 64)           16448       ['dropout_39[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 1)            65          ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,523,649\n",
            "Trainable params: 108,523,649\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(\n",
        "    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website \n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "# Set loss and metrics\n",
        "loss = CategoricalCrossentropy(from_logits = True)\n",
        "metric = CategoricalAccuracy('balanced_accuracy'),\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = [Precision(), Recall()])#metric)"
      ],
      "metadata": {
        "id": "RTY_BW6g1MaN"
      },
      "id": "RTY_BW6g1MaN",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_history = model.fit(\n",
        "    x = {'input_ids': x_train['input_ids'],'attention_mask': x_train['attention_mask']} ,\n",
        "    y = y_train,\n",
        "    validation_data = (\n",
        "    {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']}, y_test\n",
        "    ), epochs=1, batch_size=32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouUZpySm1QbH",
        "outputId": "ae42327b-7b01-47d6-defb-c4e9b3929726"
      },
      "id": "ouUZpySm1QbH",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "63/63 [==============================] - 331s 5s/step - loss: 0.0000e+00 - precision_2: 0.9458 - recall_2: 0.9842 - val_loss: 0.0000e+00 - val_precision_2: 0.9461 - val_recall_2: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(\n",
        "    {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']},\n",
        "    y_test\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BRdnWkC9j_I",
        "outputId": "210a89c0-a3e0-44d8-d04c-22b8b17ab608"
      },
      "id": "6BRdnWkC9j_I",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 17s 1s/step - loss: 0.0000e+00 - precision_2: 0.9461 - recall_2: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.946107804775238, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_history.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNa-UdCF9Nm5",
        "outputId": "73f8d277-f852-4b9b-da50-c734b5d3ddcd"
      },
      "id": "NNa-UdCF9Nm5",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.0],\n",
              " 'precision_2': [0.945767879486084],\n",
              " 'recall_2': [0.9841772317886353],\n",
              " 'val_loss': [0.0],\n",
              " 'val_precision_2': [0.946107804775238],\n",
              " 'val_recall_2': [1.0]}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score = (2 * 1 * 0.9461) / (1 + 0.9461)\n",
        "f1_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JUI0XCV1TWW",
        "outputId": "38ebb76e-d93b-4de9-b9ba-98197f4c16b4"
      },
      "id": "4JUI0XCV1TWW",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9723035815220185"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Sd8mbxZ6EvYM"
      },
      "id": "Sd8mbxZ6EvYM",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Copy of Project Tester.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}