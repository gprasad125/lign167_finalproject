{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gprasad125/lign167_finalproject/blob/main/Copy_of_Project_Tester.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f7ef64e",
      "metadata": {
        "id": "5f7ef64e"
      },
      "source": [
        "# Using Multiclass Text Classification to Analyze Famous Quotes \n",
        "\n",
        "#### Gokul Prasad & Hoang Nguyen \n",
        "#### LIGN 167, Winter 2022"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8998fd17",
      "metadata": {
        "id": "8998fd17"
      },
      "source": [
        "In this project, we'll aim to classify a variety of quotes with tags that refer to certain themes or elements specific to that particular quote. \n",
        "\n",
        "For example, Albert Einstein's quote “Life is like riding a bicycle. To keep your balance, you must keep moving.” would have tags like \"life\" or \"simile\" because it contains thematic elements about life, and contains a simile. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1773b1c2",
      "metadata": {
        "id": "1773b1c2"
      },
      "outputs": [],
      "source": [
        "# Scraping\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time \n",
        "\n",
        "# Data manipulation / cleaning / visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim as gm\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re \n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# Sklearn modeling\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2b1c8b6",
      "metadata": {
        "id": "f2b1c8b6"
      },
      "source": [
        "# Scraping and Cleaning the Data "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5efa41f",
      "metadata": {
        "id": "f5efa41f"
      },
      "source": [
        "We'll be sourcing our data from http://quotes.toscrape.com. This is a website containing 11 pages worth of quotes, each of them classified with a few tags. \n",
        "\n",
        "Firstly, we'll loop through the pages, and scrape the website HTML data with BeautifulSoup. Then, we'll use lambda functions to pull author data, quote data, and tag data. We'll put each of these into lists, and then create a pandas DataFrame to hold all our data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9738cafb",
      "metadata": {
        "id": "9738cafb",
        "outputId": "66fc2720-d2ea-435a-b732-eff047ed6eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c8b48e14-e6ff-46d0-965a-2e56fb821cb0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Author</th>\n",
              "      <th>Quote</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Albert Einstein</td>\n",
              "      <td>“The world as we have created it is a process ...</td>\n",
              "      <td>[change, deep-thoughts, thinking, world]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>J.K. Rowling</td>\n",
              "      <td>“It is our choices, Harry, that show what we t...</td>\n",
              "      <td>[abilities, choices]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Albert Einstein</td>\n",
              "      <td>“There are only two ways to live your life. On...</td>\n",
              "      <td>[inspirational, life, live, miracle, miracles]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jane Austen</td>\n",
              "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
              "      <td>[aliteracy, books, classic, humor]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
              "      <td>[be-yourself, inspirational]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8b48e14-e6ff-46d0-965a-2e56fb821cb0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8b48e14-e6ff-46d0-965a-2e56fb821cb0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8b48e14-e6ff-46d0-965a-2e56fb821cb0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Author                                              Quote  \\\n",
              "0  Albert Einstein  “The world as we have created it is a process ...   \n",
              "1     J.K. Rowling  “It is our choices, Harry, that show what we t...   \n",
              "2  Albert Einstein  “There are only two ways to live your life. On...   \n",
              "3      Jane Austen  “The person, be it gentleman or lady, who has ...   \n",
              "4   Marilyn Monroe  “Imperfection is beauty, madness is genius and...   \n",
              "\n",
              "                                             Tags  \n",
              "0        [change, deep-thoughts, thinking, world]  \n",
              "1                            [abilities, choices]  \n",
              "2  [inspirational, life, live, miracle, miracles]  \n",
              "3              [aliteracy, books, classic, humor]  \n",
              "4                    [be-yourself, inspirational]  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "page = 1\n",
        "\n",
        "authors_lst = []\n",
        "quotes_lst = []\n",
        "tags_lst = []\n",
        "\n",
        "\n",
        "while page < 11: \n",
        "    url = 'http://quotes.toscrape.com/page/{}'.format(page)\n",
        "    \n",
        "    time.sleep(10)\n",
        "    scrape = requests.get(url)\n",
        "    parsed = BeautifulSoup(scrape.content, \"html.parser\")\n",
        "    \n",
        "    curr_authors = list(map(lambda x: x.text, parsed.find_all(class_ = \"author\")))\n",
        "    curr_quotes = list(map(lambda x: x.text, parsed.find_all(class_ = 'text')))\n",
        "    \n",
        "    tag_groups = parsed.find_all(\"div\", class_ = \"tags\")\n",
        "\n",
        "    curr_tags = []\n",
        "    for i in range(len(tag_groups)):\n",
        "\n",
        "        tags = tag_groups[i].find_all(\"a\", class_ = \"tag\")\n",
        "\n",
        "        curr_group = []\n",
        "        for tag in tags:\n",
        "\n",
        "            curr_group.append(tag.text)\n",
        "\n",
        "        curr_tags.append(curr_group)\n",
        "    \n",
        "    authors_lst += curr_authors\n",
        "    quotes_lst += curr_quotes\n",
        "    tags_lst += curr_tags\n",
        "    \n",
        "    page += 1\n",
        "    \n",
        "data = {\"Author\":authors_lst, \"Quote\":quotes_lst, \"Tags\":tags_lst}\n",
        "df = pd.DataFrame(data)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "289aba52",
      "metadata": {
        "id": "289aba52"
      },
      "source": [
        "As we can see, our dataset contains some pretty messy strings in all 3 columns. We'll need to process the data to make sure it's usable for our modeling later on. \n",
        "\n",
        "For quotes, we'll first make all characters lowercase, and then use regex functionality to substitute any non alphanumeric / whitespace character with a blank string. \n",
        "\n",
        "For example, if we input a quote like \"I love. LIGN 167!!?\" we would receive an output of \"i love lign 167\". We'll apply this to our Author and Quote columns to clean them up and make them much more simplified strings. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bbad6f0",
      "metadata": {
        "id": "6bbad6f0"
      },
      "outputs": [],
      "source": [
        "def quotes_cleaning(text):\n",
        "    \n",
        "    text = text.lower()\n",
        "    \n",
        "    text = re.sub('[^A-Za-z0-9\\s]', '', text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "df['Quote'] = df['Quote'].apply(quotes_cleaning)\n",
        "df['Author'] = df['Author'].apply(quotes_cleaning)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86a10b2c",
      "metadata": {
        "id": "86a10b2c"
      },
      "source": [
        "For the tags, we have to a slightly more complicated function since the data is tucked into lists. Firstly, we'll make it a string, and use regex to remove the surrounding brackets, remove non-word characters, and replace all multi-whitespaces with a single space. We'll then render the string as a list again, and return the list. \n",
        "\n",
        "For example, if we input a list like [deep?, wonderous.., love-happy], we would get an output of [deep, wonderous, love, happy]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7baedccc",
      "metadata": {
        "id": "7baedccc"
      },
      "outputs": [],
      "source": [
        "def tags_cleaning(text):\n",
        "    \n",
        "    text = re.sub('[\\[ \\]]', ' ', str(text))\n",
        "    text = re.sub('[^\\w]', ' ', text)\n",
        "    text = re.sub('[\\s]', ' ', text)\n",
        "    \n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    return text.split(' ')\n",
        "\n",
        "df['Tags'] = df['Tags'].apply(tags_cleaning)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55f4e5cf",
      "metadata": {
        "id": "55f4e5cf"
      },
      "source": [
        "Now, having cleaned the dataset more fully, we can see the impact on our data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21f6be24",
      "metadata": {
        "id": "21f6be24",
        "outputId": "74049ca7-6054-4ced-8cdc-89cffe695203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2ccca29e-45e8-4543-8daf-e5b30346800b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Author</th>\n",
              "      <th>Quote</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>albert einstein</td>\n",
              "      <td>the world as we have created it is a process o...</td>\n",
              "      <td>[change, deep, thoughts, thinking, world]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jk rowling</td>\n",
              "      <td>it is our choices harry that show what we trul...</td>\n",
              "      <td>[abilities, choices]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>albert einstein</td>\n",
              "      <td>there are only two ways to live your life one ...</td>\n",
              "      <td>[inspirational, life, live, miracle, miracles]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jane austen</td>\n",
              "      <td>the person be it gentleman or lady who has not...</td>\n",
              "      <td>[aliteracy, books, classic, humor]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>marilyn monroe</td>\n",
              "      <td>imperfection is beauty madness is genius and i...</td>\n",
              "      <td>[be, yourself, inspirational]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ccca29e-45e8-4543-8daf-e5b30346800b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ccca29e-45e8-4543-8daf-e5b30346800b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ccca29e-45e8-4543-8daf-e5b30346800b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Author                                              Quote  \\\n",
              "0  albert einstein  the world as we have created it is a process o...   \n",
              "1       jk rowling  it is our choices harry that show what we trul...   \n",
              "2  albert einstein  there are only two ways to live your life one ...   \n",
              "3      jane austen  the person be it gentleman or lady who has not...   \n",
              "4   marilyn monroe  imperfection is beauty madness is genius and i...   \n",
              "\n",
              "                                             Tags  \n",
              "0       [change, deep, thoughts, thinking, world]  \n",
              "1                            [abilities, choices]  \n",
              "2  [inspirational, life, live, miracle, miracles]  \n",
              "3              [aliteracy, books, classic, humor]  \n",
              "4                   [be, yourself, inspirational]  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "982252e6",
      "metadata": {
        "id": "982252e6"
      },
      "source": [
        "# Reshaping Data for Modeling "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce5b9174",
      "metadata": {
        "id": "ce5b9174"
      },
      "source": [
        "Now, while the data is cleaned, we can't really model accurately when our tags are all in a list. Inputting them into our sklearn Pipelines later would not work as we would want, so we have to find a way to reshape the dataframe. Firstly, we'll need to collect the minimum and maximum amount of tags, which we do as follows. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "708238d7",
      "metadata": {
        "scrolled": true,
        "id": "708238d7",
        "outputId": "a1038478-c937-4325-b2b6-db874b40a623"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Tags'].apply(lambda x: len(x)).max()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12fc3047",
      "metadata": {
        "id": "12fc3047"
      },
      "source": [
        "So we see that the maximum amount of tags a quote could have would be 11 tags. So, let's generate a function that will make each list of tags equivalent by adding the necessary number of None values to make it to a list of length 11. \n",
        "\n",
        "For example, an input of [life, duck, nature] would yield [life, duck, nature, None, None, None, None, None, None, None, None]. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cf95757",
      "metadata": {
        "id": "7cf95757"
      },
      "outputs": [],
      "source": [
        "def tag_to_column(tags):\n",
        "    \n",
        "    sub = 11 - len(tags)\n",
        "        \n",
        "    total = tags + [None] * sub\n",
        "    return total"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f200c1a6",
      "metadata": {
        "id": "f200c1a6"
      },
      "source": [
        "Now we can apply that function to our Tags column, and use pandas get_dummies() functionality to reshape our dataframe to where each tag is a column, and the column contains 1s or 0s, reflecting whether or not a particular tag is in the quote belonging to that row. \n",
        "\n",
        "Unfortunately, pd.get_dummies() will create some duplicates so we'll groupby and sum to combine the duplicate tag columns. \n",
        "\n",
        "We then combine this dataframe with our original dataframe, and drop our tags columns. We can see the finished result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa43dfb7",
      "metadata": {
        "scrolled": true,
        "id": "aa43dfb7",
        "outputId": "cfec0119-02a3-40c6-ccf8-c8024aadf3c9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Author</th>\n",
              "      <th>Quote</th>\n",
              "      <th>tag_</th>\n",
              "      <th>tag_abilities</th>\n",
              "      <th>tag_activism</th>\n",
              "      <th>tag_adulthood</th>\n",
              "      <th>tag_adventure</th>\n",
              "      <th>tag_age</th>\n",
              "      <th>tag_alcohol</th>\n",
              "      <th>tag_aliteracy</th>\n",
              "      <th>...</th>\n",
              "      <th>tag_ups</th>\n",
              "      <th>tag_value</th>\n",
              "      <th>tag_wander</th>\n",
              "      <th>tag_wisdom</th>\n",
              "      <th>tag_women</th>\n",
              "      <th>tag_world</th>\n",
              "      <th>tag_write</th>\n",
              "      <th>tag_writers</th>\n",
              "      <th>tag_writing</th>\n",
              "      <th>tag_yourself</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>albert einstein</td>\n",
              "      <td>the world as we have created it is a process o...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jk rowling</td>\n",
              "      <td>it is our choices harry that show what we trul...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>albert einstein</td>\n",
              "      <td>there are only two ways to live your life one ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 158 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Author                                              Quote  tag_  \\\n",
              "0  albert einstein  the world as we have created it is a process o...     0   \n",
              "1       jk rowling  it is our choices harry that show what we trul...     0   \n",
              "2  albert einstein  there are only two ways to live your life one ...     0   \n",
              "\n",
              "   tag_abilities  tag_activism  tag_adulthood  tag_adventure  tag_age  \\\n",
              "0              0             0              0              0        0   \n",
              "1              1             0              0              0        0   \n",
              "2              0             0              0              0        0   \n",
              "\n",
              "   tag_alcohol  tag_aliteracy  ...  tag_ups  tag_value  tag_wander  \\\n",
              "0            0              0  ...        0          0           0   \n",
              "1            0              0  ...        0          0           0   \n",
              "2            0              0  ...        0          0           0   \n",
              "\n",
              "   tag_wisdom  tag_women  tag_world  tag_write  tag_writers  tag_writing  \\\n",
              "0           0          0          1          0            0            0   \n",
              "1           0          0          0          0            0            0   \n",
              "2           0          0          0          0            0            0   \n",
              "\n",
              "   tag_yourself  \n",
              "0             0  \n",
              "1             0  \n",
              "2             0  \n",
              "\n",
              "[3 rows x 158 columns]"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "column_renames = {0:'tag_1',1:'tag_2',2:'tag_3',3:'tag_4',4:'tag_5',5:'tag_6',6:'tag_7',7:'tag_8',8:'tag_9',9:'tag_10', 10:'tag_11',}\n",
        "\n",
        "tags = pd.DataFrame(df['Tags'].apply(tag_to_column).tolist()).rename(columns = column_renames)\n",
        "\n",
        "tags_df = pd.get_dummies(tags, prefix = 'tag')\n",
        "tags_df = tags_df.groupby(tags_df.columns, axis=1).sum()\n",
        "combined = pd.concat([df, tags_df], axis = 1).drop(columns = ['Tags'])\n",
        "combined.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45b11d4a",
      "metadata": {
        "id": "45b11d4a"
      },
      "source": [
        "We can see the distribution of tags as below. 31% of our quotes only have 1 tag, while only 1% have the maximum tags possible. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b538dc55",
      "metadata": {
        "id": "b538dc55",
        "outputId": "0d708326-1ddd-44c5-aa26-187311d5bf14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1     0.31\n",
              "2     0.23\n",
              "3     0.20\n",
              "4     0.11\n",
              "5     0.06\n",
              "6     0.03\n",
              "8     0.03\n",
              "7     0.02\n",
              "11    0.01\n",
              "dtype: float64"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "rowsums = combined.iloc[:,2:].sum(axis=1)\n",
        "cnt = rowsums.value_counts()\n",
        "\n",
        "cnt.plot(kind = 'bar')\n",
        "cnt / cnt.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbd0454d",
      "metadata": {
        "id": "cbd0454d"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f709dcc",
      "metadata": {
        "id": "6f709dcc"
      },
      "source": [
        "Now, we can begin our modeling. \n",
        "\n",
        "Firstly, we'll get a list of all of our tags. We'll do this by taking all columns besides \"Author\" and \"Quote\"\n",
        "\n",
        "Next, we'll use sklearn's train_test_split() function to split our dataset into a training and testing set. We'll split so that our test set is 33% of our dataset size. As we have 100 rows into our data, then we'll have a training set of 67 rows and testing size of 33 rows. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2adcc28",
      "metadata": {
        "id": "a2adcc28",
        "outputId": "378e0cec-6c12-47b5-b078-82acc6f647a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(67,)\n",
            "(33,)\n"
          ]
        }
      ],
      "source": [
        "tags = combined.columns.tolist()[2:]\n",
        "\n",
        "train, test = train_test_split(combined, random_state=42, test_size=0.33, shuffle=True)\n",
        "\n",
        "X_train = train.Quote\n",
        "X_test = test.Quote\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42696382",
      "metadata": {
        "id": "42696382"
      },
      "source": [
        "### Model 1: Decision Tree Classifier\n",
        "\n",
        "Our first model will be using scikit-learn Pipelines. \n",
        "\n",
        "Inside our pipeline, we'll firstly vectorize the input data by converting the quote to their TFIDF formation. This will convert our string Quotes to becoming numerical values for input. Then, we have to consider how we will be handling multiple classes. We'll try with a OneVsRest classifier, because this will allow us to pass in each tag and use an single-class estimator on each tag's train and test data. \n",
        "\n",
        "However, we need to wrap the OneVsRest classifier around an estimator that makes sense for what we are trying to achieve here. We'll use a Decision tree classifier, because the sklearn functionality is pretty simplistic, doesnt require much shaping of the data, and should hopefully set a good basis for our first try. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6d3b9cf",
      "metadata": {
        "id": "f6d3b9cf"
      },
      "outputs": [],
      "source": [
        "dt_classifier = Pipeline([('tfidf', TfidfVectorizer()), ('clf', OneVsRestClassifier(DecisionTreeClassifier()))])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcfc7702",
      "metadata": {
        "id": "dcfc7702"
      },
      "source": [
        "Now, we'll loop through each of the tags in our dataset, train our model on that particular tag, and then append it to a dictionary containg each tag and that tag's associated evaluation score. \n",
        "\n",
        "For our evaluating metric, we'll choose to use f1 scores over accuracy, because if we look at our data, we have an imbalance of tags. Some quotes have several tags, while others only have one or two. As such, using accuracy would likely not work well for this scenario. \n",
        "\n",
        "However, we have multiple classes, so it would not make much sense to get a bunch of f1 scores since each tag would give different results. We can instead collect each tag's precision and recall from when the model's predictions are compared to the actual test data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29223acb",
      "metadata": {
        "id": "29223acb"
      },
      "outputs": [],
      "source": [
        "accuracies = {}\n",
        "for tag in tags:\n",
        "    \n",
        "    dt_classifier.fit(X_train, train[tag])\n",
        "    prediction = dt_classifier.predict(X_test)\n",
        "    \n",
        "    acc = precision_recall_fscore_support(test[tag], prediction, average = 'macro')\n",
        "    accuracies[tag] = acc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42c71ad3",
      "metadata": {
        "id": "42c71ad3"
      },
      "source": [
        "So now we can calculate the average precision and recall for our tags by looping through our dictionary, summing up the total of both metrics, and dividing by the number of tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5590eb64",
      "metadata": {
        "id": "5590eb64"
      },
      "outputs": [],
      "source": [
        "sum_precision = 0\n",
        "sum_recall = 0\n",
        "\n",
        "for key in accuracies.keys():\n",
        "    \n",
        "    sum_precision += accuracies[key][0]\n",
        "    sum_recall += accuracies[key][1]\n",
        "    \n",
        "mean_precision = sum_precision / len(accuracies.keys())\n",
        "mean_recall = sum_recall / len(accuracies.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8f60216",
      "metadata": {
        "id": "d8f60216"
      },
      "source": [
        "Now we apply the formula of finding an f1 score which is (2 * p * r) / (p + r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d942fa49",
      "metadata": {
        "id": "d942fa49",
        "outputId": "dc4dae7e-d8fa-4982-8289-648b1adfff67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.708565482990131"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "average_f1 = (2 * mean_precision * mean_recall) / (mean_precision + mean_recall)\n",
        "average_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6039cf1",
      "metadata": {
        "id": "c6039cf1"
      },
      "source": [
        "So we have an f1 score of about 0.708. F1 scores range from 0 to 1, and the closer they are to 1, the better the model, so we have set up a good baseline for ourselves. But we want to improve on this and make our model better classify our quotes. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93fd599",
      "metadata": {
        "id": "b93fd599"
      },
      "source": [
        "#### Optimizing Model 1  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68c5ea4e",
      "metadata": {
        "id": "68c5ea4e"
      },
      "source": [
        "Now that we have our baseline model, how can we optimize it? \n",
        "\n",
        "There are many concepts we can implement into our Pipeline, both from a text classification standpoint, as well as a sklearn standpoint. \n",
        "\n",
        "The first method we'll implement is getting rid of stop-words. These are words that appear extremely frequently in human language, and give very little value to our model. Removing them can allow our model to focus more strongly on the more important data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41bbe4f3",
      "metadata": {
        "id": "41bbe4f3"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "919b4ad4",
      "metadata": {
        "id": "919b4ad4"
      },
      "source": [
        "Now that we have defined the words to remove, we can try and optimize our other parameters with GridSearchCV. First, we'll need to select what parameters we can optimize. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07867f2b",
      "metadata": {
        "id": "07867f2b"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'clf':(DecisionTreeClassifier(),),\n",
        "    'clf__max_depth': [2, 3, 4, 5, 7, 10, 13, 15, 18, None],\n",
        "    'clf__min_samples_split': [2, 3, 5, 7, 10, 15, 20],\n",
        "    'clf__min_samples_leaf': [2, 3, 5, 7, 10, 15, 20]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7342d553",
      "metadata": {
        "id": "7342d553"
      },
      "source": [
        "Now we have created the parameters, we can place that into a GridSearchCV and train it on our data. \n",
        "Let's print out the best parameters we get. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b22152f",
      "metadata": {
        "id": "5b22152f",
        "outputId": "1482a845-56e3-4682-ab4d-c9490b506ba4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'clf': DecisionTreeClassifier(max_depth=2, min_samples_leaf=2),\n",
              " 'clf__max_depth': 2,\n",
              " 'clf__min_samples_leaf': 2,\n",
              " 'clf__min_samples_split': 2}"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grids = GridSearchCV(dt_classifier, param_grid = parameters, cv = 3, return_train_score = True)\n",
        "for tag in tags:\n",
        "    grids.fit(X_train, train[tag])\n",
        "\n",
        "grids.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e25b700",
      "metadata": {
        "id": "9e25b700"
      },
      "source": [
        "Let's now re-run our training, testing, and calculating of precision and recall to calculate a new and hopefully improved average f1 score. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeb2a078",
      "metadata": {
        "id": "eeb2a078",
        "outputId": "c46bf01b-2feb-48a1-b9d0-375f4eb9c6f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.771879675599829"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt_classifier = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words = stop_words)), \n",
        "    ('clf', OneVsRestClassifier(DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 2)))])\n",
        "\n",
        "accuracies = {}\n",
        "for tag in tags:\n",
        "    \n",
        "    dt_classifier.fit(X_train, train[tag])\n",
        "    prediction = dt_classifier.predict(X_test)\n",
        "    \n",
        "    acc = precision_recall_fscore_support(test[tag], prediction, average = 'macro')\n",
        "    accuracies[tag] = acc\n",
        "\n",
        "sum_precision = 0\n",
        "sum_recall = 0\n",
        "\n",
        "for key in accuracies.keys():\n",
        "    \n",
        "    sum_precision += accuracies[key][0]\n",
        "    sum_recall += accuracies[key][1]\n",
        "    \n",
        "mean_precision = sum_precision / len(accuracies.keys())\n",
        "mean_recall = sum_recall / len(accuracies.keys())\n",
        "\n",
        "average_f1 = (2 * mean_precision * mean_recall) / (mean_precision + mean_recall)\n",
        "average_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e679a6a3",
      "metadata": {
        "id": "e679a6a3"
      },
      "source": [
        "So we see a decent improvement from 0.7 --> 0.77, achieved with GridSearchCV and stop_word inclusion to optimize our model. However, we'll take a look at other models / optimizations to see if we can get a heightened score. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84a537a2",
      "metadata": {
        "id": "84a537a2"
      },
      "source": [
        "### Model 2: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d450b54d",
      "metadata": {
        "id": "d450b54d"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "954fe385",
      "metadata": {
        "id": "954fe385"
      },
      "outputs": [],
      "source": [
        "x = df.drop(columns = ['Tags'])\n",
        "y = df['Tags']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        " \n",
        "y_label = mlb.fit_transform(y)\n",
        "y_label.shape"
      ],
      "metadata": {
        "id": "nSjwWWF5Fz9c",
        "outputId": "cab6d6ee-cd31-40bd-f01c-ef18493cec3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nSjwWWF5Fz9c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 156)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(df['Quote'].values)\n",
        "\n",
        "print(len(tokenizer.word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szLcfIqSSfXA",
        "outputId": "cd184d80-b44a-4426-976e-af09f944d184"
      },
      "id": "szLcfIqSSfXA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_quotes = tokenizer.texts_to_sequences(df['Quote'].values)\n",
        "token_quotes = pad_sequences(token_quotes)\n",
        "token_quotes.shape"
      ],
      "metadata": {
        "id": "yZn5RwyuIsI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bafbaab6-a8af-4548-df30-9eb54a68282d"
      },
      "id": "yZn5RwyuIsI2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 198)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y_label, test_size = 0.3)"
      ],
      "metadata": {
        "id": "h9sfMoCnKTIw"
      },
      "id": "h9sfMoCnKTIw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "input_dim = token_quotes.shape[0] + 1\n",
        "model.add(Embedding(input_dim, 100, input_length=x.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(13, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "5T7XG1y6aqEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcaf28d2-3e30-497a-b41b-64a4b8fb012e"
      },
      "id": "5T7XG1y6aqEW",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 2, 100)            10100     \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 2, 100)           0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 13)                1313      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 91,813\n",
            "Trainable params: 91,813\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, validation_split=0.3, epochs=10, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "w3O0eIYopBCH",
        "outputId": "54a1dd5f-dfff-4f5d-ef7e-43601ced1ff5"
      },
      "id": "w3O0eIYopBCH",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-e0085c4585fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1790, in categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 156) and (None, 13) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vEp3_FHwrQ5R"
      },
      "id": "vEp3_FHwrQ5R",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Copy of Project Tester.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}